Propositional satisfiability (SAT) solvers are designed to check the satisfiability of a given propositional logic formula. SAT solvers have advanced significantly in recent years, which has fueled their applications in a wide range of domains. Mainstream modern SAT solvers are based on the CDCL algorithm Marques- Silva & Sakallah (2003). It mainly relies on two kinds of variable related heuristics: 1) the variable branching heuristic Moskewicz et al. (2001); Liang et al. (2016), for deciding which variables are the best to branch on; 2) the phase selection heuristic Pipatsrisawat & Darwiche (2007); Biere & Fleury (2020); Fleury & Heisinger (2020), for deciding which phase (i.e., value) a variable should have.  

Recently, Graph Neural Networks (GNNs) have been proposed to improve CDCL SAT solvers by enhancing these two heuristics. However, this approach has not usually made solvers more effective Jaszczur et al. (2020); Kurin et al. (2019); Han (2020). One exception is NeuroCore Selsam & Bjørner (2019) which aims to improve the variable branching heuristic in CDCL SAT solvers by predicting the variables involved in the unsatisfiable (unsat) core (i.e., a subset of the SAT formula that remains unsat). It performs frequent online model inferences to adjust its unsat core prediction with dynamic information extracted from the SAT solving process. As a result, NeuroCore helps two classic CDCL SAT solvers called MiniSat and Glucose solve more problems in the main track of SATCOMP- 2018 Heule et al. (2018).  

However, frequent online inferences cause NeuroCore computationally intensive during its application. The demand on GPU resources escalate, especially when deployed in parallel, a prevalent way for utilizing SAT solvers to tackle complex problems Hamadi et al. (2010); Schreiber & Sanders (2021); Martins et al. (2012). Obviously, lacking GPU resources would become the major bottleneck of NeuroCore's parallel performance. Note that, the setup of NeuroCore's experiments called for network access to 20 GPUs distributed over five machines to support 400 parallel NeuroCore runs.
We propose NeuroBack, a novel approach to make CDCL SAT solving more effective and avoid frequent online model inferences, thus making the GNN approach more practical. The main idea of NeuroBack is to make offline model inference, i.e., prior to the solving process, to obtain instructive static information for improving CDCL SAT solving. Once trained, the offline model inference allows NeuroBack to execute solely on the CPU, thereby making it completely independent of GPU resources. In particular, NeuroBack seeks to refine the phase selection heuristics in CDCL solvers by leveraging offline neural predictions on variable phases appearing in the majority (or even all) of the satisfying assignments.  

The offline predictions on such phase information are based on the generalization of backbone variables, which are variables whose phases remain consistent across all satisfying assignments. Recent work Biere et al. (2021); Al- Yahya et al. (2022) has shown that backbone variables are crucial for enhancing CDCL SAT solving. Choosing the correct phase for a backbone variable prevents conflicts, while an incorrect choice inevitably leads to backtracking in the search. Moreover, predicting the correct phases of non- backbone variables appearing in the majority of satisfying assignments is also important, because such phases prevent backtracking with high probabilities. Our conjecture is that the knowledge learned from predicting the phases of backbone variables can be transferred to predicting the phases of non- backbone variables exhibited in the majority of satisfying assignments. Therefore, NeuroBack applies a GNN model, trained solely on predicting the phases of backbone variables, to predict the phases of all variables.  

NeuroBack converts the SAT formula with diverse scales into a compact and more learnable graph representation, turning the problem of predicting variable phases into a binary node classification problem. To make the GNN model both compact and robust, NeuroBack employs a novel Graph Transformer architecture with light- weight self- attention mechanisms. To train the model with supervised learning, a balanced dataset called DataBack containing 120,286 labeled formulas with diversity was created from five different sources: CNFgen Lauria et al. (2017), SATLIB Hoos & Stützle (2000), model counting competitions from 2020 to 2022 MCC (2020; 2021; 2022), and main and random tracks in SAT competitions from 2004 to 2021.  

To evaluate the effectiveness of our approach, NeuroBack is incorporated into a state- of- the- art CDCL SAT solver called Kissat Biere & Fleury (2022), resulting in a new solver called NeuroBack- Kissat. The experimental results on all SAT problems from SATCOMP- 2022 SAT (2022) and SATCOMP- 2023 SAT (2023) show that NeuroBack allows Kissat to solve up to \(5.2\%\) and \(7.4\%\) more problems, respectively. The experiments thus demonstrate that NeuroBack is a practical neural approach to improving CDCL SAT solvers. The contributions of our paper are:  

1. Approach. To our knowledge, NeuroBack presents the first practical neural approach to make the CDCL SAT solving more effective, without requiring any GPU resource during its application.  

2. Dataset. A new dataset DataBack containing 120,286 data samples is created for backbone phase classification. DataBack is publicly available at https://huggingface.co/datasets/neuroback/DataBack  

3. Implementation. NeuroBack is incorporated into a state-of-the-art SAT solver, Kissat. The source code of NeuroBack model and NeuroBack-Kissat is publicly available at https://github.com/wenxiwang/neuroback.