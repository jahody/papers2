This section presents related work on identifying the backbone and machine learning techniques for improving CDCL SAT solving.
<center>Figure 1: Overview of NeuroBack. First, the input CNF formula is converted into a compact and more learnable graph representation. A trained GNN model is then applied once on the graph before SAT solving begins for phase selection. The SAT solver utilizes phase information in the resulting labeled graph as an initialization to guide its solving process. Thus, with the offline process of making instructive phase predictions, NeuroBack makes the solving more effective and practical. </center>  

Backbone for CDCL Solvers. Janota proved that identifying the backbone is co- NP complete Janota (2010). Furthermore, Kilby et al. demonstrated that even approximating the backbone is generally intractable Kilby et al. (2005). Wu Wu (2017) applies a logistic regression model to predict the phase of backbone variables to improve a classic CDCL SAT solver called MiniSat Eén & Sörensson (2003). Although the approach correctly predicts the phases of \(78\%\) backbone variables, it fails to make improvements over MiniSat in solving time. In addition, recent works Biere et al. (2021); Al- Yahya et al. (2022) have been focusing on enhancing CDCL SAT solving by employing heuristic search to partially compute the backbone during the solving process. In contrast, NeuroBack applies GNN to predict the backbone in an offline manner to obtain the phase information of all variables to improve CDCL solving.  

Machine Learning for CDCL Solvers. Recently, several approaches have been developed to utilize GNNs to facilitate CDCL SAT solving. NeuroSAT Selsam et al. (2018) was the first such framework adapting a neural model into an end- to- end SAT solver, which was not intended as a complete SAT solver. Others Jaszczur et al. (2020); Davis et al. (1962); Kurin et al. (2019); Han (2020); Audemard & Simon (2018); Zhang & Zhang (2021) aim to provide SAT solvers with better branching or phase selection heuristics. These approaches either reduce the number of solving iterations or enhance the solving effectiveness on selected small- scale problems with up to a few thousand variables. However, they do not provide obvious improvements in solving effectiveness for large- scale problems.  

In contrast, NeuroCore Selsam & Bjørner (2019), the most closely related approach to this paper, aims to make the solving more effective especially for large- scale problems as in SAT competitions. It enhances the branching heuristic for CDCL using supervised learning to map unsat problems to unsat core variables (i.e., the variables involved in the unsat core). Based on the dynamically learned clauses during the solving process, NeuroCore performs frequent online model inferences to tune the predictions. However, this online inference is computationally demanding. NeuroBack is distinct from NeuroCore in two main aspects. One, while NeuroCore is designed to refine the branching heuristic in CDCL SAT solvers, NeuroBack is invented to enhance their phase selection heuristics. Two, while NeuroCore extracts dynamic unsat core information from unsat formulas through online model inferences, NeuroBack captures static backbone information from sat formulas using offline model inference. Details of NeuroBack are introduced in the following section.