In all experiments, we set the feature dimension \(\mathrm{d} = 64\) and the number of messagepassing iterations \(\mathrm{T} = 5\) for training. The model architecture consists of two Graph Attention Network (GAT) layers followed by a Multi- Layer Perceptron (MLP) layer (in a sequential connection). The initial number of attention heads is 4, and this number increases by 1 every 1000 training steps until reaching a maximum of 8. All experiments are conducted on a server equipped with a single NVIDIA A100 GPU and 8 CPU cores.  

We first follow the experiment settings in recent work NSNet. Specifically, we run experiments using the same subset of BIRD benchmark [31] , which contains eight categories arising from DQMR networks, grid networks, bit- blasted versions of SMTLIB benchmarks, and ISCAS89 combinatorial circuits. Each category has 20 to 150 CNF formulas, which we split into training/testing with a ratio of \(70\% /30\%\) . Note that the BIRD benchmark is quite small and contains large- sized formulas with more than 10,000 variables and clauses, it challenges the generalization ability of our model. Besides evaluating in such a data- limited regime, we also conduct experiments on the SATLIB benchmark, an open- source dataset containing a broad range of CNF formulas collected from various distributions. To train our model effectively, we choose the distributions with at least 100 satisfiable instances, which include the following 5 categories: (1) uniform random 3- SAT on phase transition region (RND3SAT), (2) backbone- minimal random 3- SAT (BMS), (3) random 3- SAT with controlled backbone size (CBS), (4) "Flat" graph coloring (GCP), and (5) "Morphed" graph coloring (SW- GCP). The whole dataset has 46,200 SAT instances with the number of variables ranging from 100 to 600, and we split it into training/validation/testing sets with a ratio of \(60\% /20\% /20\%\) . For both BIRD and SATLIB benchmarks, we ran the state- of- the- art exact #SAT solver DSharp [24] with a time limit of 5,000 seconds to generate the ground truth labels. The instances where DSharp fails to finish within the time limit are discarded.