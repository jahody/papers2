Modeling a Boolean CNF formula \(f\) as a CSP instance \(\mathcal{I} = (\mathcal{X},\mathcal{D},\mathcal{E})\) is straightforward. The set of variables \(\mathcal{X}\) in \(\mathcal{I}\) is  

simply the set of variables in \(f\) and all domains are given by \(\mathcal{D}(X) = \{0,1\}\) . For each clause \(c\) in \(f\) we add one constraint \(C\) to \(\mathcal{I}\) with the same scope of variables as \(c\) and the relation \(R^{C} = \{0,1\}^{k}\backslash \{t_{c}\}\) . Here, \(k\) is the arity of \(c\) and \(t_{c}\in \{0,1\}^{k}\) is the one combination of values that does not satisfy \(c\) .  

Data We train on the distribution \(\Omega_{\mathrm{3SAT}}\) of random uniform 3SAT instances with 100 variables and a clause/variable ratio sampled uniformly between 4 and 5. This density is roughly where the threshold of satisfiability for random 3- SAT is. Many of these instances are unsatisfiable. For validation, we use formulas with 200 variables and the same density distribution.  

Baselines PDP is also trained on \(\Omega_{\mathrm{3SAT}}\) . We used the default PDP configuration for all other options. RLSAT can not be trained on our distribution, since its reward expects all training instances to be satisfiable. Furthermore, their training procedure is relatively sensitive and requires a Curriculum Learning to train well. We, therefore, use the curriculum for 3- SAT provided by the authors of RLSAT. Training is performed on a sequence of data sets with increasing variable counts 5, 10, 25, 50 and finally 100. This training data is generated by their generators.  

We also evaluate the conventional algorithms WalkSAT and probSAT. For WalkSAT we tuned the "walk probability" and "noise" parameters but found the default configuration to perform best. We do run probSAT in its default configuration as well since it has internal heuristics that choose parameters based on the arity of the instance.  

We run all methods for 10K steps on each instance. We adopt the experimental setting from RLSAT and run each method 10 times on every instance and take the best attempt as the output. PDP is deterministic and we run it only once.