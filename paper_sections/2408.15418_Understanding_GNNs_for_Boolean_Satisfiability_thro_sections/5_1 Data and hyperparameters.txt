5.1.1 Data Generation. Selsam et al. [29] demonstrates that a well- structured distribution of training data is essential to prevent the model from overfitting to superficial features. A recent theoretical study [26] also explains why input diversity is important in order for the model to transition to a regime where it is performing optimization over inputs. We therefore reuse Selsam's generative model of random SAT formulas which makes sure that no superficial features exist. The generative model samples random clauses until the formula becomes unsatisfiable. Once it finds such unsatisfiable formula, it flips one literal in the lastly generated clause, and this will produce another formula which will differ by one literal and will be satisfiable.  

However, Selsam's generation procedure is largely random and therefore does not capture any human- like reasoning skills. Therefore we also generate structured problems (Latin squares, Sudoku, and logical circuits). For the interested reader, we describe the details of the data generation process in the Supplementary materials S3.1 and S3.2.  

In the reference implementation of NeuroSAT, the model is trained on 100 000 formulas where for each formula the number of variables is sampled uniformly from the interval [10, 40]. The model is then evaluated on problems with 40 variables. Similarly as in the original paper, this test set is here referred to as \(SR(40)\) . In our case, the size of the test set is the same, but we train only on 10 000 formulas in total and sample the number of variables in the formula from the interval [5, 40]. We emphasize that in the experimental results, all models are trained on the same training data.  

5.1.2 Model architecture. When experimenting with the original NeuroSAT architecture, we found that it is unnecessarily complex without any clear rationale and therefore we tried to simplify it as much as possible. We managed to significantly simplify the model without sacrificing the final accuracy. Here is the list of simplifications in our model:  

We completely removed the two 3- layer MLPs that produce the messages from the hidden states of the two LSTMs. The messages sent are, therefore, the hidden states themselves. We replace the final voting MLP with a linear layer. We do not use LayerNorm within LSTMs. We reduce the dimension of the hidden state of the LSTMs from 128 to 16.  

5.1.3 Training loop. We train the model using the curriculum described in Section 3. In the following text, we consider the size of the formula to be given by the number of variables it contains. The training starts with formulas of size 5 and this size is incremented by 2 every time the validation accuracy (for a given size) reaches a given threshold or the maximum number of 200 epochs is reached. For each increment, we add the problems from the four previous increments 3 which makes the training more stable. The thresholds used to increment the size are obtained by interpolating the values between 0.65 (for the first size) and 0.85 (for the last size). We note that the values could be set to a fixed number but this may waste time during learning on the intermediate sizes. Empirically, the model spends most of the time on the first 3 and 5 last sizes. For the other training hyperparameters, we follow the original implementation except that we change the learning rate to \(2 \cdot 10^{- 3}\) .