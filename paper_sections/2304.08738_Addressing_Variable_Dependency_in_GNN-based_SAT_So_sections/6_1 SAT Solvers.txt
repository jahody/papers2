There are two main categories of machine- learning- based SAT solvers: the end- to- end SAT solvers and the solvers using machine- learning as just the heuristics. NeuroSAT [Selsam et al., 2018], DG- DAGRNN [Amizadeh et al., 2018] and our AsymSAT all belong to the first category, where machine learning methods are used to directly predict the SAT outcome. In the second category, machine learning methods only serve as a heuristic, guiding the classic algorithms. For example, NeuroCore [Selsam and Bj√∏rner, 2019] used GNN to compute scores for variable selection in SAT solving and NLocal- SAT [Zhang et al., 2020] used GNN to predict one potential solution as the starting point of the stochastic local search (SLS) process. There are also other techniques to support SAT solving. For example, QuerySAT proposed to use multiple SAT queries to increase accuracy [Ozolins et al., 2021], and [Li et al., 2022] suggested it is helpful to transfer SAT problems from different application domains to a unified underlying distribution.  

Although in this paper we mainly investigate the importance of addressing variable dependency in the end- to- end ML SAT solvers (the first category), we argue that our technique is general and may benefit neural SAT solvers in the second category as well. For example, in NLocal- SAT, if we  

can provide a more accurate initial guess with the help of a tie- breaker proposed in this paper, the later stochastic local search process may be able to reach a satisfying solution with less searching effort.