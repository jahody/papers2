Preferential Labeling [Sun et al., 2022] is another method that can potentially break the tie between two symmetric variables in GNN- based SAT solving. It assigns distinct initial embeddings to variables, so symmetric nodes can therefore be distinguished. However, biased initialization also introduces artefact for GNN. In order to smooth out the artefact, each round of training or inference must evaluate the network under multiple random permutations of the initial embeddings. In the training phase, Preferential Labeling picks the permutation that produces the lowest loss and only optimizes the network parameters under this permutation. Meanwhile, the inference process takes the averaged output among all attempted permutations as the final prediction. Compared to Preferential Labeling, we regard our method as a lower- cost solution for tie- breaking in SAT solving. Our appendix details the comparison on performance and cost.