Effectiveness of div Gate Table 3 compares our div gate- based model with direct division for conditional probability prediction. Across all settings, div gates yield consistently lower MAE, e.g., reducing error from 0.1173 to 0.0312 with one moderate condition. This highlights their advantage in numerical stability and learning robustness, while direct division suffers from unstable gradients and sensitivity to small denominators.
Table 3: Ablation study on the effectiveness of using div gates for computing conditional probability (MAE). Here, "#Cond." indicates the number of condition nodes involved.   

<table><tr><td rowspan="2"># Cond.</td><td colspan="2">Moderate Condition</td><td colspan="2">Polar Condition</td></tr><tr><td>div gate</td><td>direct division</td><td>div gate</td><td>direct division</td></tr><tr><td>1</td><td>0.0312</td><td>0.1173</td><td>0.0395</td><td>0.7129</td></tr><tr><td>2</td><td>0.0339</td><td>0.1495</td><td>0.0423</td><td>0.7940</td></tr><tr><td>5</td><td>0.0368</td><td>0.2030</td><td>0.0486</td><td>0.8546</td></tr></table>  

Table 4: Ablation study on the effectiveness of our two-stage training strategy (MAE).   

<table><tr><td># Condition Nodes</td><td>Two-stage</td><td>Only Stage-1</td><td>Only Stage-2</td></tr><tr><td>1</td><td>0.0331</td><td>0.0422</td><td>0.0435</td></tr><tr><td>2</td><td>0.0352</td><td>0.0583</td><td>0.0493</td></tr><tr><td>5</td><td>0.0387</td><td>0.0738</td><td>0.0588</td></tr></table>  

Effectiveness of Training Strategy We evaluate the effectiveness of our two- stage training strategy, where stage1 learns fine- grained behavior from a 100- pattern simulation and stage- 2 captures broader statistical distributions using 20,000- pattern data. As shown in Table 4, the two- stage model consistently achieves the lowest L1 loss, outperforming both stage- 1 and stage- 2 models individually. For instance, with one condition node, L1 loss improves from 0.0422 (stage- 1) and 0.0435 (stage- 2) to 0.0331 (two- stage).  

Additionally, the second- stage model accelerates inference, reducing the time by a factor of 200 compared to stage- 1, which needs 200 invocations to simulate the 20,000- pattern workload.