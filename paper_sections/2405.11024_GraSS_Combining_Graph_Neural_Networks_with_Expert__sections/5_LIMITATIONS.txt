Although our experiments strongly establish the superiority of our approach in the presented scenario, several limitations can be noted. Deep learning methods are well- known to be data hungry, and perform best in regimes where training sets are large. It is plausible that in scenarios where a limited number of timed instances are available, performance would not be competitive against simpler models. In addition, in many scenarios it might be desirable to learn online, updating models as examples stream in: our method cannot be readily adapted to this situation, as training requires runtime labels on every solver for each instance, and adapting graph neural networks to online learning is challenging [42].