Evaluation with random initialization. LS- based SAT solvers typically begin by randomly initializing an assignment and then iteratively flip variables guided by specific heuristics until reaching a satisfying assignment. To compare the behaviors of GNNs with this solving procedure, we first conduct an evaluation of GNN models with randomized initial embeddings in both training and testing, emulating the initialization of LS SAT solvers.  

The results presented in Table 6 demonstrate that using random initialization has a limited impact on the overall performances of GNN- based SAT solvers. This suggests that GNN models do not aim to learn a fixed latent representation of each formula for satisfiability prediction and satisfying assignment prediction. Instead, they have developed a solving strategy that effectively exploits the inherent graph structure of each SAT instance.  

Table 6: Results using random initialization. Values in parentheses denote the difference between the results with learned initialization.   

<table><tr><td rowspan="2">Task</td><td rowspan="2">Method</td><td colspan="2">Easy Datasets</td><td colspan="2">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan="2">T1</td><td>NeuroSAT</td><td>97.24 (+1.24)</td><td>96.44 (+0.11)</td><td>77.29 (-0.91)</td><td>84.85 (-0.05)</td></tr><tr><td>GGNN</td><td>96.78 (+0.03)</td><td>96.38 (+0.13)</td><td>76.97 (-0.15)</td><td>85.80 (+0.69)</td></tr><tr><td rowspan="2">T2</td><td>NeuroSAT</td><td>79.09 (-0.70)</td><td>80.79 (+0.20)</td><td>37.27 (+0.02)</td><td>40.75 (-0.86)</td></tr><tr><td>GGNN</td><td>80.10 (-0.90)</td><td>79.83 (+0.51)</td><td>32.85 (-0.52)</td><td>36.59 (+0.64)</td></tr></table>  

Evaluation on the predicted assignments. Under random initialization, we further analyze the solving strategies of GNNs by evaluating their predicted assignments decoded from the latent space. For the task of satisfiability prediction, we employ the 2- clustering decoding algorithm to extract the predicted assignments from the literal embeddings of NeuroSAT at each iteration of message passing. For satisfying assignment
prediction, we evaluate both NeuroSAT and GGNN using multiple- prediction decoding. Our evaluation focuses on three key aspects: (a) the number of distinct predicted assignments, (b) the number of flipped variables between two consecutive iterations, and (c) the number of unsatisfiable clauses associated with the predicted assignments.  

<center>Figure 5: Results on the predicted assignments with the increased message passing iteration \(T\) . NeuroSAT\* refers to the model trained for satisfiability prediction. </center>  

As shown in Figure 5, all three GNN models initially generate a wide array of assignment predictions by flipping a considerable number of variables, resulting in a notable reduction in the number of unsatisfiable clauses. However, as the iterations progress, the number of flipped variables diminishes substantially, and most GNN models eventually converge towards predicting a specific assignment or making minimal changes to their predictions when there are no or very few unsatisfiable clauses remaining. This trend is reminiscent of the greedy solving strategy adopted by the LS solver GSAT (Selman et al., 1992), where changes are made to minimize the number of unsatisfied clauses in the new assignment. However, unlike GSAT's approach of flipping one variable at a time and incorporating random selection to break ties, GNN models simultaneously modify multiple variables and potentially converge to a particular unsatisfied assignment and find it challenging to deviate from such a prediction. It is also noteworthy that despite being trained for satisfiability prediction, NeuroSAT\* demonstrates similar behavior to the GNN models trained for assignment prediction. This observation indicates that GNNs also learn to search for a satisfying assignment implicitly in the latent space while performing satisfiability prediction. To provide more insights into the strengths and limitations of GNN- based heuristics, we further conduct experiments to compare GNN- based SAT solvers against state- of- the- art CDCL and LS- based SAT solvers in Appendix D.2.