We compare the probability prediction error (PE, see Eq. (13)) and runtime (Time) with previous DeepGate. The previous DeepGate is denoted as DeepGate and our proposed model with novel loss function and GNN design is named as DeepGate2 in Table I. Based on the results presented in the table, we make two observations. First, our proposed DeepGate2 exhibits more accurate predictions of logic probability compared to the previous version. On average, the probability prediction error (PE) of DeepGate2 is \(13.08\%\) lower than that of DeepGate. This suggests that using the novel model architecture with embedding initialization strategy can benefit logic representation learning and lead to better results on logic probability prediction. Second, our DeepGate2 performs more efficient than DeepGate. Take the circuit D1 as an example, DeepGate requires 36.89 seconds for inference, but our DeepGate2 only needs 2.23s, which is 16.56x faster than the previous DeepGate. Moreover, compared to the previous model, DeepGate2 achieves an order of magnitude speedup (16.43x on average) in model runtime. This is attributed to the fact that the GNN model in DeepGate relies on 10 forward and 10 backward message propagation, whereas the proposed one- round GNN model in DeepGate2 only performs forward propagation for 1 time. Therefore, the new circuit representation learning model is more effective and efficient than DeepGate, and demonstrates the generalization ability on large- scale circuits.