Selsam and Bjørner (2019) propose to train supervised models that predict the UNSAT- core membership of variables and then use the model prediction to guide branching heuristics. Following their methodology, we phrase the task of predicting whether or not a variable occurs in an UNSAT- core as a variable- level binary classification task and train a GNN for this problem in a supervised manner using a standard cross- entropy loss. The ground- truth on training and validation instances is computed by extracting the cores from DRAT UNSAT proofs generated by the CaDiCaL Biere et al. (2024) solver. Note that these cores are not minimal, as computing such would not be feasible. As discussed in Section 3.2, the extracted cores on our unsatisfiable 3SAT training instances contain all variables for almost all instances and are therefore not a meaningful training target. We therefore only train UNSAT- core prediction models for 3COL and CRYPTO. We train a separate model for each distribution and restrict training to the unsatisfiable instances.  

Note that Selsam and Bjørner (2019) integrate their prediction by periodically resetting the VSIDS scores of the guided CDCL- solver to prediction logits of the GNN. This requires careful tuning of the reset frequency. It is also specific to solvers based on the VSIDS heuristic and would, for example, not be applicable to the March solver. Furthermore, in later ablation experiments, Selsam and Bjørner (2019) report that the performance improvement obtained with a trained GNN is barely distinguishable from when an untrained, randomly initialized model is used, further questioning the effectiveness of guiding solvers with this strategy. To facilitate a direct and fair comparison with RLAF- trained policies, we instead combine the UNSAT- core predictions with our own solver guidance based on multiplicative weights. For a variable \(x\) , let \(p_{\mathrm{core}}(x)\) be the predicted probability of \(x\) being in an UNSAT- core according to the trained GNN model. Then we transform these probabilities to variable weights through the following transformation:  

\[w(x) = 1 + \alpha \cdot p_{\mathrm{core}}(x). \quad (21)\]  

Here, \(\alpha \geq 0\) is a parameter that determines how the variable weight scales with the raw model predictions. For this experiment, we found weights of \(w(x) \geq 1\) to perform better, hence the offset of 1 in Equation (21). The value of \(\alpha\) is tuned on the corresponding validation dataset in the range \(\{10^{- 4}, 10^{- 3}, 10^{- 2}, 10^{- 1}, 10^{0}, 10^{1}, 10^{2}, 10^{3}, 10^{4}\}\) . We tune \(\alpha\) separately for both Glucose and March. The polarities are simply set to \(p(x) = 1\) as the prediction of UNSAT- core membership has no clear implication for the sign of the branching literal. Using this methodology, we found that the UNSAT- core predictions can significantly accelerate both base solvers, although by a smaller margin than RLAF- trained policies.