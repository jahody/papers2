We modify existing SAT solvers to incorporate external variable weights into their branching heuristic. Let some base SAT solver be given. We assume that this solver is a DPLL- derived backtracking search algorithm. We further assume that the branching heuristic is implemented by first selecting a variable \(\hat{x} = \mathrm{argmax}_{x} \mathrm{Score}(x)\) that maximizes some variable scoring function Score before picking a literal sign according to some secondary heuristic, as illustrated in Algorithm 2. Many existing branching heuristics, such as VSIDS and look- ahead heuristics, fit the generic algorithm pattern while relying on different definitions of variable scores. Note that these scores usually depend on the current partial assignment of the search as well as information extracted in previous search steps, such as encountered conflicts. We can modify this decision heuristic to incorporate additional variable weights \(w: \mathrm{Var}(\phi) \to \mathbb{R}_{>0}\) for the given input formula \(\phi\) :  

\[\hat{x} = \mathrm{argmax}_{x} w(x) \cdot \mathrm{Score}(x) \quad (1)\]  

These weights are passed to the modified solver as additional input and modulate its branching heuristic by scaling the variable- wise scores. In this manner, we can inject prior knowledge of variable importance into the solver's branching decisions without sacrificing its original heuristic. Naturally, choosing a useful variable weighting \(w\) by hand is difficult. Instead, our focus is on learning to infer effective variable weights from the input formula's structure using a deep neural network.  

In addition to these weights, we may also specify a mapping \(p: \mathrm{Var}(\phi) \to \{0, 1\}\) that assigns a polarity \(p(x)\) to each variable \(x\) . When \(x\) is chosen as a decision variable, the polarity determines which value is assigned to \(x\) first. Specifying polarities for variables is a common function for modern SAT solvers, and well- chosen values can have a significant impact on run time, especially on satisfiable instances. In this work, we will infer variable- wise polarities alongside the variable weights \(w\) with a learned GNN model. Overall, the modified solver \(\mathrm{Solve}(\phi , \mathcal{W})\) takes as input a CNF formula \(\phi\) as well as a variable parameterization \(\mathcal{W} = (w, p)\) that assigns a weight \(w(x) \in \mathbb{R}_{>0}\) and polarity \(p(x) \in \{0, 1\}\) to each variable \(x \in \mathrm{Var}(\phi)\) .
<center>Figure 2: a) The input formula \(\phi\) is modeled as a graph \(G(\phi)\) . b) The graph is processed by a trainable GNN and outputs a parameterization policy \(\pi_{\theta}(\phi)\) . c) The policy \(\pi_{\theta}(\phi)\) consists of independent variable-wise weight (LogNormal) and polarity (Bernoulli) distributions. d) A variable parameterization \(\mathcal{W} = (w,p)\) is sampled from \(\pi_{\theta}(\phi)\) , mapping each variable \(x\) in \(\phi\) to a weight \(w(x) \in \mathbb{R}_{>0}\) and polarity \(p(x) \in \{0,1\}\) . e) A guided SAT solver incorporates the parameterization \(\mathcal{W}\) to guide its branching heuristic. </center>