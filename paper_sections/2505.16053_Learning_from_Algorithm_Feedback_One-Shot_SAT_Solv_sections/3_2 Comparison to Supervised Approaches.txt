Prior work suggests predicting predefined variable properties, such as UNSAT core Selsam and Bj√∏rner (2019) or backbone Wang et al. (2024) membership, in a supervised manner, and then transforming model predictions into variable weights and polarities for solver guidance. Here, we aim to compare how guidance learned with RLAF compares to this approach. Note that the notions of UNSAT cores and backbones are only sensible training targets for some instance distributions. Backbones can only be non- empty on satisfiable instances, and even for satisfiable graph coloring problems, all backbones are empty due to the permutation symmetry of the vertex colors. Furthermore, on our UNSAT 3SAT training instances, we observed that the UNSAT core extracted by SAT solvers contained all variables on almost all instances, yielding a training target that is effectively constant. Due to these limitations, we use the 3SAT instances to evaluate the effectiveness of predicting the backbone, while we use the graph coloring and cryptographic instances to compare RLAF to core- based solver guidance. For a fair comparison, we use the same GNN architecture used to train with RLAF and train a separate model for each instance distribution. The transformation that maps the backbone/core predictions to variable weights is tuned separately for each instance distribution on the corresponding validation set. Full details about the setup of this comparison are provided in Appendix B.4.  

Figure 4 compares the results for Glucose in terms of the relative wall- clock runtime compared to the base solver. Overall, the policy learned with RLAF significantly outperforms solver guidance based on both UNSAT core and backbone predictions by achieving a smaller relative runtime. The backbone- based heuristic outperforms RLAF only on satisfiable 3SAT instances with 300 variables, but not on larger problems. On unsatisfiable 3SAT problems, the backbone- guided heuristic performs substantially worse. RLAF also outperforms core- based guidance for both graph coloring and cryptographic SAT problems. Overall, these results demonstrate that pure RL- based learning with RLAF can yield more effective solver guidance than predicting handcrafted notions of variable importance in a supervised manner.