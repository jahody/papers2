In our experiments<sup>2</sup>, we aim to answer two primary research questions: (i) Can RLAF train GNN- based guidance policies that shorten solver runtimes and generalize to harder formulas? (ii) How do RLAF- trained policies fare against guidance based on learning predefined notions of variable importance in a supervised manner? Furthermore, we want to understand whether the learned policies capture known variable properties after training and whether the policies learned with different solvers are related or solver- specific.  

Solvers We conduct experiments with two distinct base solvers: The well- known CDCL solver Glucose (Audemard and Simon, 2017) and the DPLL solver March (Heule et al., 2005). Glucose uses the VSIDS branching heuristic and is comparatively strong on structured problems, while March uses a look- ahead branching heuristic and is among the best- known solvers for random instances. We provide more technical details about how RLAF is integrated into both solvers in Appendix A.3.  

Data We consider three well- known classes of SAT problems with significantly different structures to study how well RLAF can adapt the base solvers to each of them. In Appendix B.1 we provide full details on the data generation and dataset statistics. Random 3SAT: We define 3SAT \((n)\) as the distribution of uniformly random 3SAT instances with \(n\) variables and clause- to- variable ratio of 4.26, which is approximately the critical density where the instances transition from SAT to UNSAT. The training data consists of 20K instances sampled from 3SAT(200). We test on larger instances with \(n \in \{300, 350, 400\}\) , where we sample 200 instances for each size \(n\) . Graph Coloring: We consider
Table 1: Results on test instances. All metrics are averaged across the respective test sets. The mean number of decisions is rounded to the nearest whole number. For results with RLAF, we include the time required for the GNN forward pass in the total runtime. We highlight numbers in bold when they are the best value achieved for the respective base solver.   

<table><tr><td colspan="2">Data</td><td rowspan="2">Result</td><td rowspan="2">Count</td><td colspan="2">Glucose</td><td colspan="2">Glucose + RLAF</td><td rowspan="2">March Decisions</td><td rowspan="2">Time (s)</td><td rowspan="2">March Decisions</td><td rowspan="2">Time (s)</td></tr><tr><td>Distribution</td><td></td><td>Decisions</td><td>Time (s)</td><td>Decisions</td><td>Time (s)</td></tr><tr><td rowspan="2">3SAT(300)</td><td>SAT</td><td>103</td><td>341,418</td><td>6.67</td><td>121,184</td><td>1.85</td><td>2,893</td><td>0.25</td><td>2,389</td><td>0.23</td></tr><tr><td>UNSAT</td><td>97</td><td>725,812</td><td>15.49</td><td>508,676</td><td>8.21</td><td>11,783</td><td>1.01</td><td>11,757</td><td>1.04</td></tr><tr><td rowspan="2">3SAT(350)</td><td>SAT</td><td>108</td><td>1,568,289</td><td>48.76</td><td>805,035</td><td>18.88</td><td>16,546</td><td>1.64</td><td>11,702</td><td>1.19</td></tr><tr><td>UNSAT</td><td>92</td><td>3,628,268</td><td>132.28</td><td>3,136,552</td><td>82.84</td><td>52,287</td><td>5.14</td><td>51,846</td><td>5.16</td></tr><tr><td rowspan="2">3SAT(400)</td><td>SAT</td><td>89</td><td>9,638,668</td><td>598.35</td><td>4,447,304</td><td>186.70</td><td>64,296</td><td>7.27</td><td>47,992</td><td>5.51</td></tr><tr><td>UNSAT</td><td>111</td><td>22,130,692</td><td>1,895.62</td><td>20,808,043</td><td>1,112.71</td><td>245,064</td><td>27.49</td><td>242,499</td><td>27.51</td></tr><tr><td rowspan="2">3COL(400)</td><td>SAT</td><td>77</td><td>15,519</td><td>0.36</td><td>6,988</td><td>0.22</td><td>926</td><td>0.22</td><td>598</td><td>0.21</td></tr><tr><td>UNSAT</td><td>123</td><td>70,692</td><td>1.99</td><td>34,920</td><td>0.81</td><td>10,563</td><td>2.61</td><td>5,954</td><td>1.57</td></tr><tr><td rowspan="2">3COL(500)</td><td>SAT</td><td>91</td><td>82,758</td><td>2.61</td><td>35,901</td><td>1.05</td><td>7,689</td><td>2.55</td><td>4,754</td><td>1.68</td></tr><tr><td>UNSAT</td><td>108</td><td>460,881</td><td>17.47</td><td>363,278</td><td>12.24</td><td>100,811</td><td>33.34</td><td>60,321</td><td>20.52</td></tr><tr><td rowspan="2">3COL(600)</td><td>SAT</td><td>87</td><td>606,598</td><td>25.03</td><td>339,378</td><td>11.59</td><td>63,512</td><td>27.16</td><td>42,862</td><td>18.71</td></tr><tr><td>UNSAT</td><td>113</td><td>3,092,344</td><td>193.96</td><td>2,811,133</td><td>155.23</td><td>754,720</td><td>313.57</td><td>461,639</td><td>197.12</td></tr><tr><td rowspan="3">CRYPTO(20)</td><td>UNSAT</td><td>100</td><td>51,294</td><td>1.16</td><td>3,541</td><td>0.15</td><td>1,203</td><td>0.82</td><td>390</td><td>0.41</td></tr><tr><td>CRYPTO(15)</td><td>UNSAT</td><td>100</td><td>225,447</td><td>5.74</td><td>64,150</td><td>1.40</td><td>52,282</td><td>34.56</td><td>8,257</td><td>6.40</td></tr><tr><td>CRYPTO(10)</td><td>UNSAT</td><td>100</td><td>3,753,850</td><td>162.45</td><td>1,520,075</td><td>64.95</td><td>679,864</td><td>467.38</td><td>230,905</td><td>169.22</td></tr></table>  

the distribution \(3\mathrm{COL}(n)\) of SAT problems that decide 3- colorability for random Erdős- Rényi graphs with \(n\) vertices. We set the edge probability such that the expected vertex degree is 4.67, which is approximately the critical density for 3- colorability where hard instances are common (Zdeborová and Krząkała, 2007). We train on 20K instances sampled from \(3\mathrm{COL}(300)\) on 200 larger problems each for \(n \in \{400,500,600\}\) . Cryptographic: We further include highly structured instances arising from SAT- based decryption attacks (Soos et al., 2009). We define \(\mathrm{CRYPTO}(n)\) as the distribution of SAT instances generated for decrypting the HiTag2 cipher (Courtois et al., 2009) with \(n\) given help bits. Note that these instances are harder for smaller values of \(n\) and are mostly UNSAT. We train on 20K instances from \(\mathrm{CRYPTO}(22)\) and test on harder problems with \(n \in \{20,15,10\}\) .  

Hyperparameters We train a different model for each solver and each SAT problem class. We configure the GNN with 10 layers with embedding dimension \(d = 256\) . We train for \(K = 2000\) GRPO iterations. In every iteration, we use \(N = 100\) training formulas and collect feedback for \(M = 40\) variable parameterizations for each formula. The SAT solver runs are parallelized across all CPU cores. The model is trained for 50 steps of SGD in each GRPO iteration. Each training run uses a machine equipped with a single H100 GPU, an Intel Xeon 8468 CPU with 48 cores, and 128GB of RAM. The total runtime of all training runs is between 24h and 48h.