Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve circuit- sat: An unsupervised differentiable approach. In International conference on learning representations, 2018.
Jacob Austin, Daniel D Johnson, Jonathan Ho, Daniel Tarlow, and Rianne Van Den Berg. Structured denoising diffusion models in discrete state- spaces. Advances in neural information processing systems, 34:17981- 17993, 2021.  

Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of satisfiability, volume 185. IOS press, 2009.  

Sally C Brailsford, Chris N Potts, and Barbara M Smith. Constraint satisfaction problems: Algorithms and applications. European journal of operational research, 119(3):557- 581, 1999.  

Chen Cai, Truong Son Hy, Rose Yu, and Yusu Wang. On the connection between mpnn and graph transformer. In International conference on machine learning, pages 3408- 3430. PMLR, 2023.  

Shengze Cai, Zhiping Mao, Zhicheng Wang, Minglang Yin, and George Em Karniadakis. Physics- informed neural networks (pinns) for fluid mechanics: A review. Acta Mechanica Sinica, 37 (12):1727- 1738, 2021.  

James M Crawford and Larry D Auton. Experimental results on the crossover point in random 3- sat. Artificial intelligence, 81(1- 2):31- 57, 1996.  

Jerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical analysis. Cognition, 28(1- 2):3- 71, 1988.  

Zhaohui Fu and Sharad Malik. On solving the partial max- sat problem. In International Conference on Theory and Applications of Satisfiability Testing, pages 252- 265. Springer, 2006.  

Bernd Gärtner and Jiri Matousek. Approximation algorithms and semidefinite programming. Springer Science & Business Media, 2012.  

Michel X Goemans and David P Williamson. Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. Journal of the ACM (JACM), 42(6):1115- 1145, 1995.  

Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek- r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025.  

Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840- 6851, 2020.  

Abdelrahman Hosny and Sherief Reda. torchmsat: A gpu- accelerated approximation to the maximum satisfiability problem. arXiv preprint arXiv:2402.03640, 2024.  

Jan Hula, David Mojžíšek, and Mikoláš Janota. Understanding gnns for boolean satisfiability through approximation algorithms. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, pages 953- 961, 2024.  

Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El- Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card. arXiv preprint arXiv:2412.16720, 2024.  

Anastasios Kyrillidis, Anshumali Shrivastava, Moshe Vardi, and Zhiwei Zhang. Fourier sat: A fourier expansion- based algebraic framework for solving hybrid boolean constraints. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 1552- 1560, 2020.
Zhaoyu Li and Xujie Si. Nsnet: A general neural probabilistic framework for satisfiability problems. Advances in Neural Information Processing Systems, 35:25573- 25585, 2022. Zhaoyu Li, Jinpei Guo, and Xujie Si. G4satbench: Benchmarking and advancing sat solving with graph neural networks. arXiv preprint arXiv:2309.16941, 2023. Gary Marcus. Deep learning: A critical appraisal. arXiv preprint arXiv:1801.00631, 2018. Gary F Marcus. The algebraic mind: Integrating connectionism and cognitive science. MIT press, 2003. Leland McInnes, John Healy, and James Melville. Umap: Uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426, 2018. Preetum Nakkiran, Arwen Bradley, Hattie Zhou, and Madhu Advani. Step- by- step diffusion: An elementary tutorial. arXiv preprint arXiv:2406.08929, 2024. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural sat solver. In 2022 International joint conference on neural networks (IJCNN), pages 1- 8. IEEE, 2022. Motakuri Ramana and Alan J Goldman. Some geometric results in semidefinite programming. Journal of Global Optimization, 7(1):33- 50, 1995. Bart Selman, Henry A Kautz, Bram Cohen, et al. Local search strategies for satisfiability testing. Cliques, coloring, and satisfiability, 26:521- 532, 1993. Daniel Selsam and Nikolaj Bjorner. Guiding high- performance sat solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing- SAT 2019: 22nd International Conference, SAT 2019, Lisbon, Portugal, July 9- 12, 2019, Proceedings 22, pages 336- 353. Springer, 2019. Daniel Selsam, Matthew Lamm, Benedikt Binz, Percy Liang, Leonardo de Moura, and David L Dill. Learning a sat solver from single- bit supervision. arXiv preprint arXiv:1802.03685, 2018. Qiao Sun, Zhicheng Jiang, Hanhong Zhao, and Kaiming He. Is noise conditioning necessary for denoising generative models? arXiv preprint arXiv:2502.13129, 2025. Zhiqing Sun and Yiming Yang. Difusco: Graph- based diffusion solvers for combinatorial optimization. Advances in neural information processing systems, 36:3706- 3731, 2023. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. W Wang, Y Hu, M Tiwari, S Khurshid, KL McMillan, and R Miikkulainen. Neurocomb: improving sat solving with graph neural networks, 2021. David Warde- Farley, Vinod Nair, Yujia Li, Ivan Lobov, Felix Gimeno, and Simon Osindero. Solving maxsat with matrix multiplication. arXiv preprint arXiv:2311.02101, 2023. Morris Yau, Nikolaos Karalias, Eric Lu, Jessica Xu, and Stefanie Jegelka. Are graph neural networks optimal approximation algorithms? Advances in Neural Information Processing Systems, 37:73124- 73181, 2024. Emre Yolcu and Barnabas Póczos. Learning local search heuristics for boolean satisfiability. Advances in Neural Information Processing Systems, 32, 2019.
<center>Figure 6: Validation accuracy during training. Our model with a curriculum achieves reaches \(85\%\) in approximately 30 minutes, whereas the original NeuroSAT implementation needs over 5 hours. For comparison, we also add our implementation trained on the same data, but without a curriculum. The training of each model stops once it achieves an accuracy of \(85\%\) on a validation set. </center>