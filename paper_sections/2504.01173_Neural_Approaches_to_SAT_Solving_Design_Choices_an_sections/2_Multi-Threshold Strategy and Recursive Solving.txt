In the partial assignment extraction step, setting a lower threshold allows for the selection of as many assignments as possible at each step, thereby greatly simplifying the problem; however, it is more likely to select unreliable assignments that may lead to contradictions. To balance this, we adopt a multi- threshold list, starting from the lowest threshold. For each given threshold, if a new partial assignment is obtained, unit propagation is used to update the clauses and evaluate:  

If the simplified clause set becomes empty, all clauses are satisfied and the final solution is directly returned. If a conflict occurs or the recursive call at the next level fails, the threshold is raised; if the highest threshold is reached, the process moves to the next recursive level and performs another diffusion step. If unit propagation succeeds but the problem is not yet completely solved, the process recurses to the next level, performing a diffusion step on the updated clauses. If the recursion reaches a preset maximum depth and the clauses still cannot be satisfied, the recursion at that level fails.
Table 9: Performance on SR100 for Different Diffusion Step and Fixed GNN Step. Note that the Performance is no longer Significantly Improved when Diffusion Steps Larger than 8.   

<table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>25</td><td>4</td><td>0.991</td><td>69.9</td></tr><tr><td>25</td><td>5</td><td>0.901</td><td>71.2</td></tr><tr><td>25</td><td>6</td><td>0.798</td><td>72.7</td></tr><tr><td>25</td><td>8</td><td>0.705</td><td>73.0</td></tr><tr><td>25</td><td>10</td><td>0.728</td><td>72.1</td></tr><tr><td>25</td><td>20</td><td>0.662</td><td>73.3</td></tr><tr><td>25</td><td>30</td><td>0.676</td><td>72.3</td></tr><tr><td>25</td><td>40</td><td>0.655</td><td>73.3</td></tr><tr><td>25</td><td>50</td><td>0.663</td><td>73.0</td></tr></table>  

Table 10: Performance on SR100 for Different GNN Step and Fixed Diffusion Step. Note that the Performance is no longer Significantly Improved when GNN Steps Larger than 50.   

<table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>10</td><td>10</td><td>2.028</td><td>55.0</td></tr><tr><td>20</td><td>10</td><td>0.846</td><td>68.6</td></tr><tr><td>30</td><td>10</td><td>0.622</td><td>74.4</td></tr><tr><td>40</td><td>10</td><td>0.578</td><td>75.5</td></tr><tr><td>50</td><td>10</td><td>0.533</td><td>77.6</td></tr><tr><td>60</td><td>10</td><td>0.518</td><td>77.2</td></tr><tr><td>70</td><td>10</td><td>0.500</td><td>78.6</td></tr><tr><td>80</td><td>10</td><td>0.521</td><td>77.9</td></tr><tr><td>90</td><td>10</td><td>0.512</td><td>77.6</td></tr><tr><td>100</td><td>10</td><td>0.522</td><td>77.4</td></tr></table>  

Table 7 shows the performance and computational cost after applying unit propagation. We tested a fixed model under the settings: GNN steps \(= 25\) , diffusion steps \(= 10\) , and multithreshold list \(= [0.6, 0.75, 0.9]\) . As shown, incorporating unit propagation improves accuracy by approximately \(10\%\) across various problem settings. The last three columns of the table list the number of recursive function calls during the recursion process. Since each call involves one diffusion step, the computational cost incurred by the multi- threshold strategy is directly reflected. We observed that for harder problems, the computational cost of the multi- threshold strategy is actually lower, as unit propagation on partial assignments is more likely to encounter conflicts, thereby reducing the number of recursive branches.