This work provides a comprehensive analysis of graph neural networks for Boolean satisfiability problems. Our evaluation identified key design choices that enhance performance: variable- clause graph representation with RNN updates offers an effective balance of accuracy and efficiency, while our novel closest assignment supervision method significantly improves performance on problems with large solution spaces. The recurrent architecture enables flexible scaling during inference through additional message- passing iterations and resampling. Our diffusion model extension demonstrates another approach to inference- time adaptation, with further improvements possible by integrating classical techniques like unit propagation.  

Our analysis of embedding space patterns and optimization trajectories supports the interpretation that these models implicitly implement continuous relaxation algorithms for MaxSAT, explaining their ability to generalize to novel problem instances. This connection provides a theoretical framework for understanding neural reasoning capabilities in structured domains, with implications for the design of hybrid solving approaches.