Reasoning is a cognitive ability which allows humans to solve problems with previously unseen combinations of constraints. For a long time, it has been debated whether artificial neural networks can obtain such generalization skills or whether they can only learn to detect superficial patterns Fodor and Pylyshyn [1988], Marcus [2003, 2018] without being able to generalize to novel combinations of constraints. With the arrival of Large Language Models (LLMs) specially trained for reasoning Guo et al. [2025], Jaech et al. [2024], it became harder and harder to claim that these models can only detect superficial patterns. Nevertheless, the exact mechanism by which they are able to solve tasks that typically require reasoning is largely unknown and the robustness of the solving process is also not understood.  

In this contribution, we focus on a restricted class of problems that require reasoning, concretely on solving Boolean formulas in CNF form. This could be viewed as a prototypical task where the goal is to solve problems with novel combinations of constraints, and where detecting superficial patterns seen during training would be insufficient. It has already been demonstrated that Graph Neural Networks (GNNs) can successfully learn to solve such problems and generalize to larger problems Selsam et al. [2018], even though they are still not competitive when compared to state of the art SAT solvers.  

Understanding the underlying mechanisms GNNs employ to successfully solve problems, as well as their limitations, would offer significant practical and theoretical value. On the practical side, the trained model can be used as a guessing heuristic inside classical solvers, improving
their performance and on the theoretical side, understanding how a GNN can solve a CNF formula could help us to elucidate the reasoning ability of Transformers Vaswani et al. [2017] because Transformers can be viewed as GNNs in which the graph connectivity is given by the attention map and is learned from data Cai et al. [2023]. Our aim in this contribution is to provide an experimental evaluation of different design choices for GNNs in the context of Boolean satisfiability together with an intuitive explanation of the inner workings of these models. Our main contributions are as follows:  

- We provide an experimental comparison of different architectures and training regimes.- We introduce a novel supervision method based on the closest assignment, resulting in significant improvements.- We demonstrate that these architectures scale well at test time.- We extend the graph neural network to a diffusion model and show how it relates to the base model.- We provide an intuitive explanation for the inner workings of these models.  

The rest of the text has the following structure: Section 3 (Relevant Background) provides the necessary context on Boolean satisfiability problems, SAT solving approaches, graph neural networks, theoretical connection to approximation algorithms, and diffusion models. Section 4 (Experimental Setup) describes our methodology, including data representation choices, architecture variants, supervision methods, and benchmark generation. Section 5 (Experimental Results) presents our comprehensive evaluation, comparing different graph representations and training methods (Section 5.2), demonstrating test- time scaling capabilities (Section 5.3), and introducing our diffusion model extension (Section 5.4). Section 6 (Interpreting the Trained Model) offers analysis of the embedding space and explains the networks' behavior through the lens of approximation algorithms based on continuous relaxation. Section 2 (Related Work) positions our contribution within the broader research landscape, and Section 7 contains a discussion of our findings and directions for future research. We conclude in Section 8. Additional implementation details and mathematical derivations are provided in the Appendix.