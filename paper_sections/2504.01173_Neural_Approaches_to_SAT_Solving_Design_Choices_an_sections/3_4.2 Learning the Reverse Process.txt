The core idea of diffusion models is to learn the reverse process - how to gradually denoise a corrupted sample to recover the original data distribution. In our case, we train a GNN to progressively recover a satisfiable assignment \(\mathbf{x}_{0}\) starting from a random initial assignment. The trained model is used to sample from a distribution \(p(\mathbf{x}_{t - 1}|\mathbf{x}_{t})\) which can be used to obtain a an assignment \(\mathbf{x}_{0}\) from random assignment \(\mathbf{x}_{T}\) as explained bellow. There are multiple ways of training the neural network used in the diffusion model. One can train it to directly model the distribution \(p(\mathbf{x}_{t - 1}|\mathbf{x}_{t})\) . In the method introduced by Austin et al. Austin et al. [2021], the network is trained to predict the original uncorrupted input \(\mathbf{x}_{0}\) which is then used to sample from the the posterior \(p(\mathbf{x}_{t - 1}|\mathbf{x}_{t})\) using Bayes' rule. This approach provides stronger learning signals during training, as the target \(\mathbf{x}_{0}\) remains fixed regardless of a timestep and we use it within this work.