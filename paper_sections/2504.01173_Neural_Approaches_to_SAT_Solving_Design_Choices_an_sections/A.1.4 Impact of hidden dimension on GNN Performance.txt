The dimensionality of the hidden representations, here denoted as d_model, specifies the size of the embedding vectors of variables and the hidden state dimension used during the message passing and update phases within the GNN architecture.  

The choice of d_model directly influences the model's capacity to learn complex patterns and relationships within the graph structure and node features. It also impacts computational resource requirements, such as memory usage and training time. Understanding how performance metrics vary with different d_model values is therefore crucial for effective model design and hyperparameter tuning.  

Our evaluation in table 8 generally shows that increasing the d_model leads to improved model performance, likely due to the enhanced representational capacity allowing the model to capture more intricate features. However, we observed that this trend exhibits diminishing returns; while significant performance gains are noticeable as the dimension increases up to 64, further increases yield smaller improvements in accuracy relative to the growing computational cost (e.g., peak accuracy at d_model=256 came with significantly longer training time). This suggests that, considering the marginal benefits, a dimension around 64 still presents a practical optimum, offering a good balance between performance and model complexity/efficiency for this specific setup.