Our experiment design commences by segregating the two previously mentioned datasets into distinct training and testing subsets, meticulously avoiding any overlaps. We allocate \(80\%\) of the data to training, reserving the remaining \(20\%\) for testing. We benchmark against several baselines: (1) The NeuroSAT [Selsam et al., 2019] model based on GNN and Literal- clause graph. We follow the official implementation and used the score they set for variable as our proposed probality. (2) Modified version of NeuroSAT: NeuroCore [Selsam and Bj√∏rner, 2019], that target UNSAT problem. We follow the official implementation and interaction periodically with solvers. (3) NLocalSAT [Zhang et al., 2021] is based on NeuroSAT and interacts with SLS solver.
Table 2: Average running time of different CDCL solvers targeting random 100-sample UNSAT problems from LEC dataset and SAT Comp dataset   

<table><tr><td>Original Solvers</td><td>LEC</td><td colspan="2">SAT Comp</td></tr><tr><td>CaDiCaL</td><td>350s</td><td>209s</td><td></td></tr><tr><td>MiniSAT</td><td>810s</td><td>450s</td><td></td></tr><tr><td>Glucose</td><td>529s</td><td>308s</td><td></td></tr><tr><td>Kissat</td><td>335s</td><td>195s</td><td></td></tr></table>  

Table 3: Model UNSAT-core prediction performance on LEC dataset and SAT Competition dataset   

<table><tr><td rowspan="2">Approach</td><td colspan="3">LEC Circuit</td><td colspan="3">SAT Comp</td></tr><tr><td>Acc</td><td>Pos.F1</td><td>Neg.F1</td><td>Acc</td><td>Pos.F1</td><td>Neg.F1</td></tr><tr><td>NeuroCore</td><td>89%</td><td>94%</td><td>27%</td><td>85%</td><td>77%</td><td>88%</td></tr><tr><td>NeuroSAT</td><td>90%</td><td>93%</td><td>8%</td><td>77%</td><td>62%</td><td>82%</td></tr><tr><td>NLocalSAT</td><td>89%</td><td>94%</td><td>11%</td><td>74%</td><td>60%</td><td>80%</td></tr><tr><td>IB-Net</td><td>95%</td><td>97%</td><td>71%</td><td>91%</td><td>84%</td><td>93%</td></tr></table>  

We adopted the official implementation but changed the output to UNSAT- core prediction. Overall, we adopt the setting for each model according to their official codes or publications but change the target output to UNSAT- core prediction.  

Our choice of the Kissat SAT solver, a top- performing Conflict- Driven Clause Learning based solver, as the collaborating solver, is guided by the comparative analysis with other CDCL solvers. From Table 2, the superior performance exhibited by Kissat in comparison with other CDCL peers justifies the selection for our study[Biere, 2019][Sorensson and Een, 2005][Audemard and Simon, 2018]. As we just maintain an interaction with Kissat, instead of recompiling the Kissat solver, our work can be transfered to future top- performing solvers.