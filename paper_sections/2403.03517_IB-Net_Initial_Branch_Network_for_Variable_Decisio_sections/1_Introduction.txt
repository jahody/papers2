In computational theory and complexity, the Boolean Satisfiability (SAT) problem stands as a cornerstone. This decision problem, underpinned by the task of identifying the possibility of truth assignment to the Boolean expression, is known to be NP- complete and computationally demanding [Cook, 1971]. SAT is fundamental to various practical applications, including software verification, hardware design, and more [Kasi and Sarma, 2013] [Leino, 2010]. Those problems will first be reduced into the SAT formula and then apply SAT solvers. During the development of SAT solvers, various techniques have been applied to boost the efficiency of the solving process. There are currently two major categories, Stochastic Local Search (SLS) based solvers and Conflict Driven Clause Learning (CDCL) based solvers. SLS  

solvers perform initial assignments for all variables in the formula and repeatedly flip the variable assignment to maximize the internal score, which leads to a solution. The foundation of CDCL solvers are clause learning and deep backtracking search, which make assignment for one variable each time until the conflict occurs to perform analysis and backtracking.  

Following the ubiquity of SAT, its implication is particularly critical in Electronic Design Automation (EDA), the suite of software used in designing electronic systems and chips. Specifically, Logic Equivalence Checking (LEC), an essential step in verifying the correctness of a circuit design after transformation in the EDA process, leverages the efficiency of SAT solvers. LEC aims to determine whether two circuits are functionally equivalent by encoding the checking problem into Boolean expressions and applying the SAT solver. As this process is to detect the potential fault in transformation, which should exist with a small possibility, we would expect that most SAT problems in LEC are unsatisfiability (UNSAT): no possible variables assignment can be found. The SAT solver will be called by LEC for numerous times for each circuit design during the design verification stage. Thus the performance of applied SAT solvers would be the critical point to boost the efficiency of LEC process.  

In recent years, there have been some studies utilizing neural networks (NN), mostly graph neural networks (GNN), to solve SAT problems directly or assist current SAT solvers. NeuroSAT pioneers the usage of NN in SAT by proposing an end- to- end model to predict the satisfiability of an SAT problem and further predict the assignment of variables [Selsam et al., 2019]. NLocalSAT adopts the model design of NeuroSAT and uses the model to boost SLS solvers offline, modifying the initial variable assignment with the output of NN for one time [Zhang et al., 2021]. However, it utilizes SAT/UNSAT for the instances as the supervision signal, which is invalid in the LEC verification scenario. Although Neurocore focuses on UNSAT problems, it computes the variable assignment periodically, which is not suitable for high- frequency verification in LEC [Selsam and Bj√∏rner, 2019].  

Therefore, we propose the Initial Branch Network (IBNet), a framework that targets UNSAT problems and interacts with state- of- the- art CDCL solver to perform offline onetime branch initialization and boost efficiency of end- to- end SAT- solving process. We design Weighted Literal- Incidence
Graph to encode the Boolean formula and employ GNN to predict the possibility of UNSAT- core variables. By proposing novel graph node feature embedding and loss function, we address the imbalanced data distribution of problems in LEC (mostly UNSAT problems and large UNSAT- core). We evaluate IB- Net and previous works with CDCL solvers on both the open SAT Competition dataset and the real industrial dataset. IB- Net achieves a \(5.0\%\) runtime reduction per problem in the whole LEC pipeline, while other benchmarks have no effect or even runtime increase. For the open SAT Competition dataset, IB- Net gains an \(8.3\%\) runtime reduction, much higher than other works. Such experimental results show the efficiency- boosting of IB- Net. All runtimes are computed with network construction and inference time inclusive.