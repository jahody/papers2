We plot scatter graphs in Fig. 6, showing memory consumption and training time of varying sizes of data samples under different computation units. WGCN uses significantly less memory across all sizes compared to LSTM, around only \(30\%\) . This stark difference suggests that model with WGCN is memory- efficient, potentially allowing for large or complex problem- solving without compromising system resources like GPU. WGCN also demonstrates faster training speeds across all data sample sizes. On average, WGCN is found to be approximately \(40\%\) quicker than LSTM. This speed advantage can reduce the time required for training models, thereby increasing the efficiency of model development process.  

<center>Figure 6: The scalability: The memory cost (a) and training time (b) according to different number of variables. </center>