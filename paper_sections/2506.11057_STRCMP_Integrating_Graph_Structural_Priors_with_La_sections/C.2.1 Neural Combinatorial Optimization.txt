L2B [14]. The paper addresses the challenge of variable selection in the branch- and- bound (B&B) algorithm for solving mixed- integer linear programs (MILPs), where traditional expert- designed heuristics like strong branching incur prohibitive computational costs. To overcome this, the authors propose a graph convolutional neural network (GCNN) framework that leverages the natural bipartite
graph representation of MILPs – with variable and constraint nodes connected via edges representing their coefficients – to learn branching policies through imitation learning. Key innovations include encoding MILP states as bipartite graphs with constraint/variable features, designing permutation-invariant sum- based graph convolutions with prenormalization layers to handle variable- sized inputs, and training via behavioral cloning of strong branching decisions using cross- entropy loss. All configurations take the default value used in [14] for fair comparison.  

HEM [15, 16]. The paper addresses the challenge of improving cut selection in mixed- integer linear programming (MILP) solvers by simultaneously optimizing three critical aspects: which cuts to select (P1), how many to choose (P2), and their ordering (P3). Existing learning- based methods focus primarily on scoring individual cuts while neglecting dynamic cut count determination and sequence dependencies. To overcome these limitations, the authors propose a novel hierarchical sequence model (HEM) that leverages a two- level architecture: a higher- level policy predicts the ratio of cuts to select using a tanh- Gaussian distribution, while a lower- level pointer network formulates cut selection as a sequence- to- sequence learning problem to output ordered subsets. The model is trained via hierarchical policy gradient optimization within a reinforcement learning framework, where states encode MILP relaxation features and candidate cut characteristics, actions represent ordered cut subsets, and rewards correspond to solver performance metrics like primal- dual gap integral. All hyperparameters take the default value used in [15, 16] for fair comparison.  

NeuroSAT [40]. The paper proposes a message- passing neural network (MPNN) to solve the Boolean satisfiability problem by training solely on binary labels indicating satisfiability. The key innovation lies in representing SAT instances as bipartite graphs where literals and clauses are nodes connected via edges, and leveraging permutation- invariant neural architectures to process these graphs. NeuroSAT iteratively refines node embeddings through bidirectional message passing: clauses aggregate information from their constituent literals, while literals update their states based on connected clauses and complementary literals. Trained on a distribution of random SAT problems generated by incrementally adding clauses until unsat, the model learns to predict satisfiability via a cross- entropy loss on the final aggregated literal embeddings. Crucially, the architecture enforces structural symmetries (variable/clause permutation invariance, negation equivalence) and generalizes to larger instances and entirely unseen domains (e.g., graph coloring, vertex cover) at test time by simply extending the message- passing iterations, despite being trained only on small random \(n \leq 40\) problems. All configurations of this algorithm take the default used in [40] for fair comparison. Note that since NeuroSAT is a prediction framework for Boolean satisfiability problem, it is meaningless to measure the solving time for this framework over the SAT instances. Besides, the ground- truth dataset used to train the NeuroSAT model is those SAT instances can be proved/solved within timelimit \(\tau\) . Thus, we only count the number predicted to be correct of NeuroSAT (this number must be less than the number of ground- truth labels). Then, the number of timeout for NeuroSAT is equal to the total number of test instances minus the number predicted to be correct.