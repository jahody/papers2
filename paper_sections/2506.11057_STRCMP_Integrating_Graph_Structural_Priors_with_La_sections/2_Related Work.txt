Neural Combinatorial Optimization. Extensive research [14, 24, 25, 15, 16] has explored machine learning integration with combinatorial optimization for improved computational approaches to \(\mathcal{N}\mathcal{P}\) - hard problems, forming Neural Combinatorial Optimization (NCO) methods that either approximate expert heuristics or learn policies via reinforcement learning. Following Bengio et al. [7]'s taxonomy, NCO encompasses: (1) End- to- end neural solvers [8- 10], (2) ML- augmented algorithm configuration [11- 13], and (3) Hybrid methods integrating learned components into classical frameworks [14- 16]. Pointer Networks [25] represent seminal work, employing attention mechanisms [8] as dynamic pointers for CO problems, eliminating dependence on fixed output dictionaries in conventional seq2seq models [26]. The framework achieves competitive performance on convex hulls, Delaunay triangulation, and small TSP instances while generalizing to unseen sizes. In hybrid approaches, Gasse et al. [14] introduced GCNs trained via imitation learning to replace strong branching heuristics [27] in branch- and- bound algorithms for MIP solvers. While avoiding manual feature engineering through graph representations, such approaches face scalability challenges under extreme problem sizes, a key limitation of neural solver architectures. Moreover, NCO's reliance on opaque machine learning models yields policies with insufficient interpretabilityâ€”problematic for high- stakes decision- making systems demanding traceable logic [17]. Our approach addresses these gaps by furnishing optimality certificates or bounded sub- optimality guarantees via CO solver integration. By procedurally generating solver- executable code through iterative refinement, our framework ensures superior interpretability relative to black- box NCO policy learning.  

Language Models for Combinatorial Optimization Problem. Recent advances in large language models (LLMs) have spurred explorations of their applications to combinatorial optimization [20, 21, 28- 30]. Current approaches fall into two categories: (1) direct solution generation via LLM inference [18, 19], and (2) automated generation of solver- compatible formalizations [20- 22, 30]. In the first paradigm, Yang et al. [18] propose Optimization by PROmpting (OPRO), leveraging LLMs as black- box optimizers through iterative refinement of natural- language problem descriptions. While achieving comparable performance to heuristics on small TSP instances, OPRO scales poorly beyond 50 nodes due to context limitations and solution- space complexity. For the second paradigm, Romera- Paredes et al. [20] introduce FunSearch, combining evolutionary methods with LLM- guided program synthesis to obtain breakthroughs on the cap set problem [31] and generate novel bin packing heuristics [32]. Similarly, [21] develop Evolution of Heuristics (EoH), integrating evolutionary algorithms with LLMs to co- optimize natural language "thoughts" and code implementations through iterative prompting, outperforming existing methods like FunSearch in query efficiency [20]. Existing approaches predominantly employ natural language (or occasionally visual [19]) prompts combined with evolutionary frameworks for iterative code generation to solve CO problems. However, these methods universally neglect the topological structural characteristics intrinsic to combinatorial optimization problems, which are systematically exploited by human experts during algorithm design [4- 6]. Furthermore, evolutionary framework- based code generation with LLMs often necessitates multiple iterations for convergence while incurring significant computational overhead from repeated solver invocations during evaluation. To overcome these limitations, we propose a composite model that effectively incorporates structural priors of CO problems during algorithmic discovery. By developing composite architectures tailored to CO problem structures, our method substantially improves both solution quality and computational efficiency compared to existing LLM- based solving approaches.