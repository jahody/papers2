We first evaluate the performance of unsupervised methods, HyperSAT and HypOp, with a focus on their convergence. We evaluate the convergence using the primary task loss \(\mathcal{L}_{\mathrm{task}}\) from Eq. (8), which represents the sum of the weights of unsatisfied clauses. We illustrate the evolution curves of loss for HyperSAT and HypOp on the uuf250- 1065 dataset in Figure 3 as an example. All models can converge within 300 epochs. Moreover, the loss of HyperSAT is around 52, while the loss of HypOp is around 139. We can observe that HyperSAT achieves better performance than HypOp. Specifically, HyperSAT decreases the loss more quickly and achieves a lower loss value. The experimental results demonstrate that HyperSAT can be used in learning to solve Weighted MaxSAT problems.  

<center>Figure 3. The evolution of loss for HyperSAT and HypOp during an inference process of 300 epochs on the uuf250-1065 dataset. </center>