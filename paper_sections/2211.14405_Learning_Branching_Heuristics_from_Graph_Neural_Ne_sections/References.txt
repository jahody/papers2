References[1] Lin Xu, Frank Hutter, Holger H Hoos, and Kevin Leyton- Brown. Satzilla: portfolio- based algorithm selection for sat. Journal of artificial intelligence research, 32:565- 606, 2008. [2] Hong Xu, Sven Koenig, and TK Kumar. Towards effective deep learning for constraint satisfaction problems. In International Conference on Principles and Practice of Constraint Programming, pages 588- 597. Springer, 2018. [3] Daniel Selsam, Matthew Lamm, Benedikt Bünz, Percy Liang, Leonardo de Moura, and David L. Dill. Learning a SAT solver from single- bit supervision. In International Conference on Learning Representations, 2019. [4] Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. Advances in neural information processing systems, 28, 2015. [5] Zhuwen Li, Qifeng Chen, and Vladlen Koltun. Combinatorial optimization with graph convolutional networks and guided tree search. Advances in neural information processing systems, 31, 2018. [6] Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combinatorial optimization algorithms over graphs. Advances in neural information processing systems, 30, 2017. [7] Wouter Kool, Herke van Hoof, and Max Welling. Attention, learn to solve routing problems! In International Conference on Learning Representations, 2019. [8] Nikolaos Karalias and Andreas Loukas. Erdos goes neural: an unsupervised learning framework for combinatorial optimization on graphs. In Advances in Neural Information Processing Systems, volume 33, pages 6659- 6672, 2020. [9] Joseph Culberson, Yong Gao, and Calin Anton. Phase transitions of dominating clique problem and their implications to heuristics in satisfiability search. In INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, volume 19, page 78, 2005. [10] Dieter Kratsch. Algorithms. In Domination in Graphs Advanced Topics, pages 191- 232. Routledge, 2017.
[11] Maximilian Bother, Otto Kißig, Martin Taraz, Sarel Cohen, Karen Seidel, and Tobias Friedrich. What's wrong with deep learning in tree search for combinatorial optimization. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=mk0HzdqY7i1.  

[12] Noga Alon and Joel H. Spencer. The probabilistic method. 2nd edition, 2000.  

[13] Gurobi Optimization, LLC. Gurobi Optimizer Reference Manual, 2022. URL https://www.gurobi.com.  

[14] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations, 2019.  

[15] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of the 32nd International Conference on Machine Learning, volume 37, pages 448- 456, 2015.  

[16] Yoshua Bengio. Practical recommendations for gradient- based training of deep architectures. In Neural networks: Tricks of the trade, pages 437- 478. Springer, 2012.