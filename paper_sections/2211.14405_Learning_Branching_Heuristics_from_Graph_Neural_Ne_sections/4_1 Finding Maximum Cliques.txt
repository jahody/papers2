Table 1 shows the experimental results of approximation ratio (i.e. the ratio of the size of the clique we find versus the size of the maximum clique). We use the greedy approximation algorithm in [8] to find large cliques, and the maximum clique is from Gurobi [13]. The greedy approximation algorithm has two ways, fast and slow, to decode cliques using the learned probability distributions. The fast way returns quickly but with a less use of the input probability distributions compared to the slow way. We run experiments for two GNN models. These two models have the same neural network architecture as the model in [8]. The only difference is that one uses our loss function (4) and another uses the original loss function in [8]. The datasets Twitter, COLLAB, and IMDB used in the experiments are from [8] as well.