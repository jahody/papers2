Given a graph \(G = (V,E)\) , a dominating clique (DC) is a subset \(S\) of \(V\) such that \(S\) is a clique and dominates \(V\backslash S\) , i.e. \(\forall u\in V\backslash S\) , \(\exists v\in S\) such that \(\{v,u\} \in E\) . Checking the existence of a dominating clique in a graph is an NP- complete problem [10].  

Our GNN model is similar to what has been proposed in [8]. Its architecture is standard and is trained in an unsupervised way to learn a probability distribution for each vertex. Unlike [8] where the distribution is directly used to sample a solution, we use the distribution to design branching heuristics. Due to the fact that a solution to the dominating- clique problem needs to satisfy both local and global properties, designing a good loss function is much more challenging than the those used in [8] for solutions that largely require certain local properties.  

We build a probability space by defining a Bernoulli distribution for each vertex of a given graph. By the correlation inequality in the probabilistic method, we can get an approximation of the probability measure of dominating cliques in the graph. Using the approximation as the loss function of a GNN model, we hope that the approximation grows larger as much as possible. We note that in [8], the first- moment method is used in the loss function of their GNN model, which requires that the value of loss function after training is less than a constant depending on specific graphs. If the requirement is not met, the learned probability distributions do not guarantee the usefulness for the solving problem. Our loss function avoid such restrictions. In our approach, under the learned probability space, the information entropy of vertices is used in the new branching heuristic to replace the original branching heuristic of the dominating- clique solver in [9]. Our experimental results show that the learned branching heuristic can prune more search space than the original branching heuristic.  

A recent attempt towards learning branching choices in a combinatorial search was given by Li et al. (2018) [5] where they approached the maximum- independent- set problem by choosing a node that is expected to be in an optimal solution. This choice is made by assigning probabilities to the unselected nodes and choosing a node of high probability, and these probabilities are learned. In a sense, it performs a greedy selection of vertices to be added to a maximum independent set. This can be parallelized into a tree search by considering multiple probability maps of the vertices at each stage (according to a pre- chosen branching factor parameter), and continuing the selection process in each probability map. The largest independent set is found over all branches. Later, Bother et al. (2022) [11] showed that the performance of such a tree search of selections can be matched by randomly generating values in place of the learned probability map for this combinatorial problem. This is comparable to a Monte Carlo tree search.  

We contrast our work here to that of Li et al.'s tree search in that their search
tree is inherently a heuristic search algorithm while ours is an exact backtracking solver. Li et al.'s search tree is parameterized with a pre- set branching factor \(M\) (which they evaluate experimentally and suggest an ideal value of \(M = 32\) ), while our search tree branches on choices made in local structures. As we are interested in exact search, an important metric we use is in counting the branches expanded in our search tree, rather than counting the fraction of solved problems like in [5].  

In the following, we denote by \(N(v)\) the open neighborhood of a vertex \(v\) (i.e. the subset of vertices that are adjacent to \(v\) ) and \(N[v] = N(v) \cup \{v\}\) the closed neighborhood. We also denote by \([n]\) the set of integers \(\{1,2,\dots,n\}\) .