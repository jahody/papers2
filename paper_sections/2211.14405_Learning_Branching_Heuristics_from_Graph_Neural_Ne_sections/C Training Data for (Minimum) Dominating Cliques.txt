Our data is generated from \(G(n,p)\) . The work in [9] shows that the phase transition of dominating cliques happens at the exact threshold \(p = \frac{3 - \sqrt{5}}{2} \approx 0.381\) . It is also mentioned in [9] that \(p\) around 0.371 is a good empirical probability to create the instances that it is hard to predict the existence of dominating cliques. We call such instances as hard instances.
For learning a branching heuristic to find a dominating clique, our training data contains 2650 instances generated from \(G(n,p)\) with the range of \(n\) being from 75 to 800. Among these instances, 1250 instances are generated from \(G(n,p)\) with \(p\) being around 0.371 as hard instances. The remaining 1400 instances are generated from \(G(n,p)\) with \(p \in (0,0.35) \cup (0.4,1)\) . we call them easy instances as they are generated outside the phase transition and relatively easier to be solved. We use 750 hard instances and all easy instances as our training data. The remaining 500 hard instances are used as validation data and test data.  

For learning a branching heuristic to find the minimum dominating clique, we create another 1250 instances (750 instances are used in training data, and the remaining 500 instances are used as validation data and test data) from \(G(n,p)\) to replace the hard instances. The range of \(n\) of these new instances is the same as the hard instances above, but the range of \(p\) is between 0.4 and 0.41. The reason is that if a graph is dense, there are many dominating cliques with minimum size. If so, commonly used branching heuristics are powerful enough because the first- found solution is usually the minimum solution. Therefore, we choose this range of \(p\) to generate the instances such that they have some dominating cliques but only few of these dominating cliques with minimum size. Additionally, we keep the same easy instances above in the training data for finding the minimum dominating clique.