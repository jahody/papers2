We firstly evaluate the performance of both GNN models, including their convergence and the quality of predicted solution. The accuracy of prediction is reported with two values in the following paragraphs. The first one is the gap to optimal objective, which is the distance between the predicted objective and the corresponding optimal value. The predicted objective can be computed by counting the satisfied clauses given the predict solution. The other is the accuracy of assignments, which is the percentage of correctly classified variables, i.e., the assignment of a variable from the predicted solution is the same as its label. Generally, the gap to optimal objective could be a better indicator, because the optimal solution of a MaxSAT problem may not be unique.  

We have trained MS- NSFG and MS- ESFG separately on three different datasets: R2 (60, 600), R2 (60, 800) and R3 (30, 300), and illustrate the evolution curves of accuracy throughout training on R2 (60, 600) in Figure 3 as an example. All the models can converge within 150 epochs, and achieve pretty good performance. The average gaps to optimal objectives are less than 2 clauses for all the models, with the approximation ratio \(>99.5\%\) . Besides, the accuracy of assignments is around \(92\%\) (Max2SAT) and \(83\%\) (Max3SAT). There is no significant difference between the two models, while MS- ESFG performs slightly better than MS- NSFG. The experimental results show that both GNN models can be used in learning to solve MaxSAT problem.  

<center>Figure 3: The evolution of accuracy of MS-NSFG and MS-ESFG during a training process of 150 epochs on the dataset R2 (60, 600). </center>