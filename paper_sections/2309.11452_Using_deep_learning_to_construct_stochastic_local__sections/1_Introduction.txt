The application of deep learning to constraint optimization and constraint satisfaction problems has received a lot of attention in recent years, with promising results. This includes the Boolean Satisfiability problem as the prototypical NP- complete [1, 2] constraint satisfaction problem, e.g. Refs. [3, 4, 5, 6, 7, 8, 9, 10, 11].  

One practical motivation for the integration of machine learning (ML) into solvers for NP- hard optimization and decision problems is that ML models can learn structure that is present in the data for a given application, in which instances of the problem might differ in the details but still be very similar in terms of their structure. An example could be planning shifts in the same factory but on different days, or checking the compatibility of components for different configurations of a given car model. Abstractly speaking, instances of such applications can be thought of as being sampled from a distribution with only narrow support over the space of all possible instances. ML models have proven a great tool for representing complex structure in high- dimensional spaces and the hope in providing solvers with access to such solvers is that they become very efficient on typical instances under the distribution, potentially at the cost of lower performance on very untypical instances.  

There are many ways of bringing ML into solvers. The main idea of this work is to use a deep learning model, in our case a Graph Neural Network (GNN), as an oracle factory that, given a SAT instance, outputs a sampling oracle, or simply put an instance- specific distribution, that a stochastic local search (SLS) solver, a particular type of random walk algorithm, can sample from in the search process. This is in contrast to various other works that use an ML model only to generate an initial candidate solution that is then fed to an off- the- shelf solver. In Sec. 2, we provide details of our approach, Fig. 1 provides a rough sketch.
<center>Figure 1: Illustration of the general idea of this work. Left: A simple SLS solver finds a solution to a SAT instance by repeatedly and randomly updating a small subset of the variables. Middle: An oracle-based SLS solver uses samples from an oracle \(O\) that is provided as part of the input to update the variables at each iteration. Right: We use a deep learning model to train an oracle factory \(F_{\theta}\) that maps an incoming instance to an oracle which is then fed into an oracle-based. This approach is motivated by results that provide sufficient conditions for an oracle-based SLS solver to find a solution efficiently, based on properties of the oracle. </center>  

The main motivation for the approach presented in this paper is a series of breakthrough results from theoretical computer science that imply sufficient conditions for an SLS solver with access to a suitable oracle to efficiently find a solution to a SAT instance from Refs. [12, 13, 14, 15].