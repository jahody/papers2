The objective of our experiments is twofold: evaluating both BPGAT scalability and generalization capabilities. In order to assess the performance of the model, both Root Mean Squared Error (RMSE) and Mean Relative Error (MRE) metrics are reported, evaluated between the logarithm of the ground truth number of models of the input formulae \(\ln Z\) and the output of the model \(\ln \hat{Z}\) .  

As a baseline, we used ApproxMC [9,23], the state- of- the- art approximate #SAT solver, which is a randomized hashing algorithm that provides Probably Approximately Correct (PAC) guarantees.  

It would have been meaningful and interesting to compare BPGAT against other guarantee- less counters, such as ApproxCount [29] or SampleApprox [28], but unfortunately we couldn't access any open- source implementation of them.  

Scalability In order to assess the ability of our model to scale to larger problem sizes than the one seen during training, we generated several datasets following the procedure detailed in Section 4.1.  

Table 1 shows the statistics of the datasets used in this testing phase, each containing 300 labeled instances. All datasets are much larger than the one seen during training, and in particular 'Test 4' contains formulae having a number of variables which is more than ten times more the one in the training set, and a number of clauses which is almost ten times more than the ones in the training set.  

Table 2 shows the results obtained, in terms of RMSE and MRE, by BPGAT and ApproxMC.  

It is worth noting that for all the datasets tested, BPGAT outperforms ApproxMC in terms of MRE (although not in terms of RMSE). Such higher RMSE is a consequence of few outliers with a large prediction error for BPGAT (as shown in Figure 1), while most of its predictions are close to the ground truth labels, as certified by the consistently lower MRE.  

Table 1. Average number of variables, average number of clauses, average number of solutions and average time employed (in seconds) by the exact solver sharpSAT of the datasets used to test scalability.   

<table><tr><td>Dataset</td><td>Avg#var</td><td>Avg#cl</td><td>Avg#sol</td><td>Avg t (s)</td></tr><tr><td>Test 1</td><td>61.8</td><td>76.89</td><td>1.76e+19</td><td>26.71</td></tr><tr><td>Test 2</td><td>60.43</td><td>143.61</td><td>6.23e+14</td><td>211.45</td></tr><tr><td>Test 3</td><td>124.07</td><td>75.26</td><td>1.14e+21</td><td>28.5</td></tr><tr><td>Test 4</td><td>377.59</td><td>275.11</td><td>7.18e+145</td><td>286.95</td></tr></table>  

Out- of- distribution generalization The second set of tests we performed aims at evaluating the generalization capabilities of our model. The problem classes we perform experiments with are both SAT- encoded combinatorial problems ( \(k\) - dominating set, graph
Table 2. RMSE/MRE performance of BPGAT and ApproxMC on datasets used to test scalability.   

<table><tr><td>Dataset</td><td>BPGAT</td><td>ApproxMC</td></tr><tr><td>Test 1</td><td>0.1276/0.001366</td><td>0.002025/0.001576</td></tr><tr><td>Test 2</td><td>0.3100/0.003201</td><td>0.2262/0.02003</td></tr><tr><td>Test 3</td><td>0.1748/0.001471</td><td>0.1035/0.01134</td></tr><tr><td>Test 4</td><td>1.2061/0.007433</td><td>0.4275/0.04038</td></tr></table>  

<center>Fig. 1. Distribution of the relative errors of BPGAT and ApproxMC on datasets used to test scalability. </center>  

\(k\) - coloring, \(k\) - clique detection) and network QMR (Quick Medical Reference) problems taken from the test suite of [23].  

In order to obtain SAT CNF formulae encoding the \(k\) - dominating set problem, the graph- \(k\) - coloring problem and the \(k\) - clique detection problem, we use the CNFgen tool [1]. It allows to sample graphs uniformly at random from the Erdos- Renyi random graph distribution \(G(N, p)\) (specifying the two parameters \(N > 0, p \in [0, 1]\) ) and to encode in CNF the required problem. After obtaining the CNF formulae, Minisat [10] is used to filter SAT formulae and sharpSAT [24] to obtain the number of models for each formula. Table 3 shows the statistics of the datasets used in this testing phase.  

To asses the effectiveness of our fine- tuning protocol we made the following experiments (whose results are summarized in Table 4):  

- We fine-tuned the model following the protocol described in Section 4.1. This is denoted as FT_BPGAT in Table 4;- We trained, for every distribution, the model from scratch for 500 epochs, with 250 labeled examples. This is denoted as TS_BPGAT in Table 4;- We tested BPGAT trained on random Boolean formulae (with the training protocol and the data generating procedures detailed in Section 4.1). This is denoted as BPGAT in Table 4.  

As expected, the worst performance is achieved by BPGAT, as it has never been trained on formulae coming from these distributions. Interestingly, fine- tuning a model pre- trained on small random Boolean formulae (FT_BPGAT) gives better results than the same model trained on the specific dataset (TS_BPGAT). This is relevant from the
perspective of data-efficiency because small random formulae are fast to generate (differently from other distributions) and the fine-tuning phase requires only a few tens of distribution-specific labeled samples. These results are also relevant from the time-efficiency perspective, as only retraining the model for 250 epochs is needed, for each unseen data distribution.  

Results of the comparison between our fine- tuned model (FT_BPGAT) and ApproxMC are shown in Table 5. It is worth observing that the performance of our architecture is comparable and in some cases outperforming that of ApproxMC (especially in terms of MRE).  

Table 3. Statistics of the datasets used to test generalization. Parameters under 'Domset' (which stands for dominating set), 'Color' (which stands for graph coloring) and 'Clique' (which stands for clique detection) are the pair \((N,p)\) used to generate formulae in the dataset. For all of them \(k = 3\) has been used.   

<table><tr><td>Dataset</td><td>Avg # var</td><td>Avg # cl</td><td>Avg # sol</td><td>Avg t (s)</td></tr><tr><td>Network</td><td>113.3</td><td>294.7</td><td>1.19e+20</td><td>123.9</td></tr><tr><td>Domset (15, 0.6)</td><td>38.43</td><td>510.15</td><td>203.3</td><td>3.76e-2</td></tr><tr><td>Color (10, 0.6)</td><td>65.63</td><td>294.54</td><td>572.9</td><td>3.19e-2</td></tr><tr><td>Clique (15, 0.5)</td><td>46.37</td><td>1145.73</td><td>102.2</td><td>3.86e-2</td></tr></table>  

Table 4. RMSE/MRE performance of BPGAT when fine-tuned for the specific data distribution (FT_BPGAT), when trained on the specific data distribution (TS_BPGAT) and when trained on random formulae (BPGAT).   

<table><tr><td>Dataset</td><td>FT_BPGAT</td><td>TS_BPGAT</td><td>BPGAT</td></tr><tr><td>Network</td><td>0.2580/0.005271</td><td>1.9334/0.04887</td><td>14.2839/0.3608</td></tr><tr><td>Domset</td><td>0.5508/0.04252</td><td>1.7808/0.7125</td><td>11.9190/9.5070</td></tr><tr><td>Color</td><td>1.2110/0.1774</td><td>1.3430/0.2046</td><td>26.1898/5.9593</td></tr><tr><td>Clique</td><td>0.007834/0.002475</td><td>0.01773/0.007333</td><td>1.9625/0.8983</td></tr></table>  

Table 5. RMSE/MRE comparison of BPGAT fine-tuned for the specific data distributions (FT_BPGAT) and ApproxMC.   

<table><tr><td>Dataset</td><td>FT_BPGAT</td><td>ApproxMC</td></tr><tr><td>Network</td><td>0.2580/0.005271</td><td>0.07619/0.05403</td></tr><tr><td>Domset</td><td>0.5508/0.04252</td><td>0.08155/0.02856</td></tr><tr><td>Color</td><td>1.2110/0.1774</td><td>0.09426/0.04241</td></tr><tr><td>Clique</td><td>0.007834/0.002475</td><td>0.01113/0.04795</td></tr></table>
Data and Time- efficiency The BPGAT architecture can be claimed data- efficient, as it requires only 1000 CNF small random formulae for (pre)training. Generating such training set requires \(\sim 5s\) with the procedure described in Section 4.1.  

For what concerns time efficiency, the BPGAT architecture is able to process (independently on the size of the formulae), all test instances described in this work, in a maximum of \(3s\) , without leveraging GPU acceleration. This is much less than the time needed by the exact solver sharpSAT and by the approximate solver ApproxMC, as shown in Figure 2.  

<center>Fig. 2. Runtime comparison (in seconds) of the mean time for counting the number of satisfying assignments of a formula for the datasets used in the scalability experiments. </center>