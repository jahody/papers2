<center>Figure 3: Survival plot for RB50. The x-axis gives the wall clock runtime in seconds. The y-axis counts the cumulative number of instances solved within a given time. </center>  

the action space required for REINFORCE. Note that we use vanilla REINFORCE without a baseline or critic network and we sample a single trajectory for every training instance. We found this simple version of the algorithm to be surprisingly robust and effective in our setting. Details on how the policy gradients are computed are provided in Appendix A.  

### 4.3 Implementation and Hyperparameters  

We implement ANYCSP in PyTorch 3. The code for relabeling \(G(\mathcal{I},\alpha^{(t)})\) in each iteration \(t\) is also fully based on PyTorch and is GPU- compatible. We implement generalized sparse matrix multiplication in the COO format in CUDA. This helps to increase the memory efficiency and speed of the message passes between values and constraints. We plan to publish this extension as a stand- alone software package or merge it with PyTorch Sparse to make it accessible to the broader Graph Learning community.  

We choose a hidden dimension of \(d = 128\) for all experiments. We train with the Adam optimizer for 500K training steps with a batch size of 25. Training a model takes between 24 and 48 hours, depending on the data. During training, we set the upper number of iterations to \(T_{\mathrm{train}} = 40\) . During testing, we usually run ANYCSP with a timeout rather than a fixed upper number of iterations \(T\) . All hyperparameters are provided in Appendix A.  

For each training distribution \(\Omega\) we implement data loaders that sample new instances on- the- fly in each training step. With our hyperparameters we therefore train each model on 12.5 Million sampled training instances. We use fixed subsets of 200 instances sampled from each distribution before training as validation data. The exact generation procedures for each training distribution are provided in Appendix B.  

## 5 Experiments  

We evaluate ANYCSP on a wide range of well- known CSPs: Boolean satisfiability (3- SAT) and its maximisation version  

Table 1: Results on structured Graph Coloring instances. We provide the number of instances solved with a 20 Minute timeout for both splits, each containing 50 instances with chromatic number less than 10 and at least 10, respectively.  

<table><tr><td>METHOD</td><td>COL&amp;lt;10</td><td>COLâ‰¥10</td></tr><tr><td>RUNCSP</td><td>33</td><td>-</td></tr><tr><td>CoSoCo</td><td>49</td><td>33</td></tr><tr><td>PICAT</td><td>49</td><td>38</td></tr><tr><td>GREEDY</td><td>16</td><td>15</td></tr><tr><td>DSATUR</td><td>38</td><td>28</td></tr><tr><td>HYBRIDEA</td><td>50</td><td>40</td></tr><tr><td>ANYCSP</td><td>50</td><td>40</td></tr></table>  

(MAX- \(k\) - SAT for \(k = 3,4,5\) ), graph colorability ( \(k\) - COL), maximum cut (MAXCUT) as well as random CSPs (generated by the so- called MODEL RB). These problems are of high theoretical and practical importance and are commonly used to benchmark CSP heuristics. We train one ANYCSP model for each of these problems using randomly generated instances. Recall that the process of learning problem- specific heuristics with ANYCSP is purely data- driven as our architecture is generic and can take any CSP instance as input.  

We will compare the performance of ANYCSP to classical solvers and heuristics as well as previous neural approaches. When applicable, we also tune the configuration of the classical algorithms on our validation data to ensure a fair comparison. All neural approaches run with one NVIDIA Quadro RTX A6000 GPU with 48GB of memory. All classical approaches run on an Intel Xeon Platinum 8160 CPU (2.1 GHz) and 64GB of RAM.  

MODEL RB First, we evaluate ANYCSP on general CSP benchmark instances generated by the MODEL RB (Xu and Li 2003). Our training distribution \(\Omega_{\mathrm{RB}}\) consists of randomly generated MODEL RB instances with 30 variables and arity 2. The test dataset RB50 contains 50 satisfiable instances obtained from the XCSP project (Audemard et al. 2020). These instances each contain 50 variables, domains with 23 values and roughly 500 constraints. They are commonly used as part of the XCSP Competition to evaluate state- of- the- art CSP solvers. Note that the hardness of MODEL RB problems comes from the dense, random constraint relations chosen at the threshold of satisfiability and even instances with 50 variables are very challenging. We will compare ANYCSP to three state- of- the- art CSP solvers: Picat (Zhou 2022), ACE (Lecoutre 2022) and CoSoCo (Audemard 2018). Picat is a SAT- based solver while ACE and CoSoCo are based on constraint propagation. Picat in particular is the winner of the most recent XCSP Competition (Audemard, Lecoutre, and Lonca 2022). No prior neural baseline exists for this problem.  

Figure 3 provides a the results on the RB50 dataset. All algorithms run once on each instance with a 20 Minute timeout. ANYCSP solves the most instances by a substantial margin. The second strongest approach is the CoSoCo solver which solves 34 instances in total, 8 less than ANYCSP. Within the timeout of 20 Minutes, ANYCSP will perform 500K search iterations. Recall that we set \(T_{\mathrm{train}} = 40\) . Therefore,