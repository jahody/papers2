# USING DEEP LEARNING TO CONSTRUCT STOCHASTIC LOCAL SEARCH SAT SOLVERS WITH PERFORMANCE BOUNDS  

Maximilian J. Kramer \(^{1,2}\) and Paul Boes \(^{1}\)  

\(^{1}\) Porsche Digital GmbH, 71636 Ludwigsburg, Germany \(^{2}\) Dahlem Center for Complex Quantum Systems, Freie Universit√§t Berlin, 14195 Berlin, Germany {maximilian.kramer, paul.boes}@porsche.digital m.kramer@fu- berlin.de  

## ABSTRACT  

The Boolean Satisfiability problem (SAT) is the most prototypical NP- complete problem and of great practical relevance. One important class of solvers for this problem are stochastic local search (SLS) algorithms that iteratively and randomly update a candidate assignment. Recent breakthrough results in theoretical computer science have established sufficient conditions under which SLS solvers are guaranteed to efficiently solve a SAT instance, provided they have access to suitable "oracles" that provide samples from an instance- specific distribution, exploiting an instance's local structure. Motivated by these results and the well established ability of neural networks to learn common structure in large datasets, in this work, we train oracles using Graph Neural Networks and evaluate them on two SLS solvers on random SAT instances of varying difficulty. We find that access to GNN- based oracles significantly boosts the performance of both solvers, allowing them, on average, to solve \(17\%\) more difficult instances (as measured by the ratio between clauses and variables), and to do so in \(35\%\) fewer steps, with improvements in the median number of steps of up to a factor of 8. As such, this work bridges formal results from theoretical computer science and practically motivated research on deep learning for constraint satisfaction problems and establishes the promise of purpose- trained SAT solvers with performance guarantees.  

## 1 Introduction  

The application of deep learning to constraint optimization and constraint satisfaction problems has received a lot of attention in recent years, with promising results. This includes the Boolean Satisfiability problem as the prototypical NP- complete [1, 2] constraint satisfaction problem, e.g. Refs. [3, 4, 5, 6, 7, 8, 9, 10, 11].  

One practical motivation for the integration of machine learning (ML) into solvers for NP- hard optimization and decision problems is that ML models can learn structure that is present in the data for a given application, in which instances of the problem might differ in the details but still be very similar in terms of their structure. An example could be planning shifts in the same factory but on different days, or checking the compatibility of components for different configurations of a given car model. Abstractly speaking, instances of such applications can be thought of as being sampled from a distribution with only narrow support over the space of all possible instances. ML models have proven a great tool for representing complex structure in high- dimensional spaces and the hope in providing solvers with access to such solvers is that they become very efficient on typical instances under the distribution, potentially at the cost of lower performance on very untypical instances.  

There are many ways of bringing ML into solvers. The main idea of this work is to use a deep learning model, in our case a Graph Neural Network (GNN), as an oracle factory that, given a SAT instance, outputs a sampling oracle, or simply put an instance- specific distribution, that a stochastic local search (SLS) solver, a particular type of random walk algorithm, can sample from in the search process. This is in contrast to various other works that use an ML model only to generate an initial candidate solution that is then fed to an off- the- shelf solver. In Sec. 2, we provide details of our approach, Fig. 1 provides a rough sketch.