<center>Figure 4: Performance heatmaps for a model trained on SR40 with SAT+UNSAT closest assignment supervision, showing how metrics improve with both increased iterations (columns) and resampling attempts (rows). Testing on SR40 (top), SR100 (middle), and 3SAT100 (bottom) demonstrates significant gains from both scaling dimensionsâ€”e.g., SR40 decision accuracy improves from 84% (1 sample, 25 iterations) to 93% (5 samples, 125 iterations). This two-dimensional inference-time scaling capability is consistent across benchmarks but with decreasing returns on larger problems. </center>  

model is trained to predict the solution \(\mathbf{x_0}\) only from the sample at timestep \(t\) ( \(\mathbf{x_0} = f_{\theta}(\mathbf{x_t})\) ). Concurrently to us, this fact was also discovered by Sun et al. Sun et al. [2025] (the same surname is a coincidence) and it's possible that many of the reported experiments which blindly use this conditioning would result in better values without it.  

In this simplified setup, the training examples \((\mathbf{x_0},\mathbf{x_t})\) are sampled by taking a solution of a formula \((\mathbf{x_0})\) , sampling a random \(t\) from the diffusion schedule and obtaining a corrupted version of the solution at time \(t\) ( \(\mathbf{x_t}\) ). The model is trained to predict \(\mathbf{x_0}\) from \(\mathbf{x_t}\) . The GNN is the same as in the case of assignment prediction except that it also contains a learnable embedding layer which embeds the Boolean values in the assignment \(\mathbf{x_t}\) into a vector space to obtain the initial embeddings of variables (or literals) for the first pass of message- passing.  

The only difference from the model trained for assignment prediction is therefore that the initial embeddings are not sampled randomly but obtained by embedding the perturbed assignment \(\mathbf{x_t}\) . This also means that during test time, these two approaches differ only by rounding, i.e. running the model trained for assignment prediction for 100 steps and after every 20 steps rounding the variable embeddings to vectors representing True and False is same as running the diffusion model for 5 diffusion steps where each step has 20 message- passing iterations.