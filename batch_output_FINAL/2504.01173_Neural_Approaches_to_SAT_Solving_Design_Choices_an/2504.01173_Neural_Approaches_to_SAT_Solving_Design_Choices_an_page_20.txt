Table 6: Performance Metrics for Different GNN and Diffusion Step Configurations. Variable names shown in parentheses in the original data source are omitted here for brevity.   

<table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Dec. Acc. (%)</td><td>Single-Step Avg. Gap</td><td>Single-Step Dec. Acc (%)</td></tr><tr><td>20</td><td>15</td><td>1.09</td><td>68.7</td><td>3.26</td><td>60.2</td></tr><tr><td>23</td><td>13</td><td>1.05</td><td>70.4</td><td>2.80</td><td>63.1</td></tr><tr><td>27</td><td>11</td><td>0.96</td><td>73.6</td><td>2.44</td><td>64.7</td></tr><tr><td>31</td><td>9</td><td>0.98</td><td>73.8</td><td>2.11</td><td>68.2</td></tr><tr><td>35</td><td>8</td><td>0.93</td><td>75.4</td><td>1.96</td><td>69.5</td></tr><tr><td>38</td><td>7</td><td>0.92</td><td>76.3</td><td>1.83</td><td>70.2</td></tr><tr><td>42</td><td>7</td><td>0.90</td><td>76.7</td><td>1.70</td><td>71.6</td></tr><tr><td>46</td><td>6</td><td>0.95</td><td>76.8</td><td>1.64</td><td>72.1</td></tr><tr><td>50</td><td>6</td><td>0.94</td><td>76.2</td><td>1.52</td><td>73.0</td></tr></table>  

#### 5.4.2 Interleaving Diffusion Steps with Unit Propagation  

The fact that for each diffusion step, the model outputs probabilities for two possible values, allows us to obtain a partial solution and then run a unit propagation to deduce assignment to other variables. The partial assignment can be obtained by fixing a threshold and then assigning only variables for which one of the values has a predicted probability higher than this threshold. The lower the threshold, the more variables will be fixed and the higher the probability that it will not be possible to complete the partial assignment to a satisfiable assignment.  

We therefore design a tree- search- like algorithm which first tries a low threshold in each diffusion step and if it does not find a satisfiable assignment it backtracks and increases the threshold to obtain a new partial assignment. The details of this algorithm are described in A.3 and the experimental results are reported in Table 7. As can be seen, interleaving the diffusion steps with unit propagation results in additional improvements over the base diffusion model (approximately \(10\%\) ). We explicitly mention that this experiment is provided only to show a possible avenue for further improvements and the algorithm in its current form is not optimized for speed.  

Table 7: Performance with Unit Propagation. Here we compare the performance with (U.P. Acc.) and without (Dec. Acc.) Unit Propagation, and report the computational cost of Unit Propagation, listing the average number of total recursive function calls, the average number of recursive calls in solved problems, and the average number of recursive calls in unsolved problems.   

<table><tr><td>Problems</td><td>Dec. Acc. (%)</td><td>U.P. Acc. (%)</td><td>Total Rec. Calls</td><td>Solved Rec. Calls</td><td>Unsolved Rec. Calls</td></tr><tr><td>SR40</td><td>88.4</td><td>94.2</td><td>32.864</td><td>6.701</td><td>53.546</td></tr><tr><td>SR50</td><td>86.6</td><td>93.7</td><td>29.539</td><td>6.995</td><td>47.038</td></tr><tr><td>SR60</td><td>83.3</td><td>92.2</td><td>26.414</td><td>7.526</td><td>40.204</td></tr><tr><td>SR70</td><td>79.5</td><td>89.5</td><td>24.162</td><td>6.752</td><td>35.505</td></tr><tr><td>SR80</td><td>77.6</td><td>88.0</td><td>22.604</td><td>6.917</td><td>32.219</td></tr><tr><td>SR90</td><td>74.0</td><td>85.1</td><td>22.140</td><td>7.274</td><td>30.151</td></tr><tr><td>SR100</td><td>73.4</td><td>83.7</td><td>20.363</td><td>7.129</td><td>27.074</td></tr><tr><td>SR150</td><td>63.2</td><td>75.1</td><td>17.388</td><td>7.828</td><td>20.592</td></tr><tr><td>SR200</td><td>58.0</td><td>67.5</td><td>16.270</td><td>8.710</td><td>17.868</td></tr></table>