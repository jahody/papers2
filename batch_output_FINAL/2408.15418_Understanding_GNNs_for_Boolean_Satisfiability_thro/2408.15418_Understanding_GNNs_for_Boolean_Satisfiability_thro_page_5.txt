<center>Figure 1: This figure shows how the embeddings of literals change during the MP process. We selected 3 different time steps from the 30 time steps used for this example. The 16-dimensional vectors are projected to 2D by UMAP algorithm. The colors correspond to the truth values of the final solution recovered for this formula. As can be seen, the literals progressively form two well-separated clusters of literals with the same truth value. </center>  

UMAP). The authors showed that for a large portion of correctly classified satisfiable formulas, they were able to recover a satisfying assignment by clustering the embeddings and assigning the same Boolean value to all literals within one cluster. They needed to test both possible ways of assigning Boolean values because they did not know in advance which cluster corresponds to the value true and which to the value false.  

We first confirmed their finding by running an experiment in which we removed the final voting layer and classified the formula using a Silhouette score [27] of the embeddings (capturing the quality of the discovered clusters). Concretely, we first run K- means on the embeddings of literals to assign them to two clusters and then we compute the Silhouette score with the assigned labels. On the training set, we estimate a threshold for this score and classify the test set according to this threshold (i.e., we classify a formula as satisfiable if its score is above this threshold). With this procedure, we achieve the same accuracy as the original model with the voting layer (85%), which means that the observation of cluster formation is robust.  

Next, we tested whether the model can produce different clusterings if we sample initial embeddings of literals multiple times (this corresponds to different initializations of the SDP solver). This turned out to be the case; for a large portion of satisfiable problems, using multiple random initializations of the embeddings would produce a diverse set of solutions. This enables us to substantially improve the classification accuracy by taking a majority vote over multiple initializations. The sampling of different solutions is also trivially parallelizable.  

Motivated by similarities with the SDP relaxation, we tested whether it is possible to recover the vector representing the value true and use this vector to assign a value to each literal. We selected all the formulas that the model correctly classified as satisfiable and checked whether the formula could be satisfied by one of the two possible assignments of Boolean values to the resulting clusters. Thus, we obtain a set of literal embeddings that correspond to the value true and another set corresponding to the value false, aggregated over all problems. Finally, we computed an average vector for both sets and also a distribution of Euclidean distances  

to these two vectors. Concretely, for each literal that was assigned the value true, we compute the \(l_2\) distance of its embedding to the average true vector and also to the average false vector. Similarly, for each literal that was assigned the value false.  

<center>Figure 2: A histogram of Euclidean distances to the average true vector and average false vector. 0 to 0 center are distances between embeddings of literals assigned to false to the average false vector, etc. The figure clearly demonstrates that literals that take the value false in the final assignment move to the same area of the vector space and the same is true for literals that take the value true. </center>  

Figure 2 shows that all vectors assigned to the value true are close to the average true vector and far from the average false vector, and vice versa. Therefore, we can assign each literal of a formula according to its distance to these two average vectors. Relying on the intuition from BP, we may try to treat these two distances as marginal probabilities over the two possible truth values, and therefore obtain a decimation algorithm. This algorithm fixes variables whose embeddings are close to one of these average vectors, simplifies the formula, and runs the MP of the GNN again. The results with these improvements are presented in the following section.  

## 5 Experiments  

In this section, we describe the datasets we use for evaluation, model/training hyperparameters and experimental results. The experimental results are divided into qualitative findings where we present general observations supporting the connection to SDP and quantitative findings where we compare our improvements to the original NeuroSAT model.