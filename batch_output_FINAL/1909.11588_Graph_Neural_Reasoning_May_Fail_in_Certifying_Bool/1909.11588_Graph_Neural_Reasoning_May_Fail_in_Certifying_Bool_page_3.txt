## 3 Certifying UNSAT by GNNs may Fail  

Although existing researches showed that GNN can learn a well- performed solver for satisfiability problems, GNN- based SAT solvers actually have terrible performances in predicting unsatisfiability with high confidence [12] in a SAT formula, if the formula does not have a small unsatisfiable core (minimal number of clauses that is enough to cause unsatisfiability). In fact, some previous work [1] even completely removed unsatisfiable formulas from the training dataset, since they slowed down the whole training process.  

The difficulty in proving unsatisfiability is understandable, since constructing a proof of unsatisfiability demands a complete reasoning in the search space, which is more complex than constructing a proof of satisfiability that only requires a witness. Traditionally it relies on the recursive decision procedures that either traverse all possible assignments to construct the proof (DPLL [4]), or generate extra constraints from assignment trials that lead to conflicts, until some of the constraints contradict each other (CDCL [13]). The line of recursive algorithms include some operation branches that reconfigure the bipartite graph behind the CNF in each step while they search. In the terms of a graph that may iteratively change (e.g., DPLL), perhaps miserably, their recursive processes can not be simulated by GNNs.  

Observation 3.1. Given a recursive algorithm that iteratively reconfigures the graph, GNNs in Eq.2 can not simulate this recursive process.  

Proof. Associating the aggregate and combine functions in Eq. 2, we obtain the iterative update rule for the embedding of a literal \(v\) :  

\[\begin{array}{r l} & {h_{v}^{(k)} = \mathrm{Combine}_{L}^{(k)}\left(h_{v}^{(k - 1)},h_{v - v}^{(k - 1)},\mathrm{Aggregate}_{L}^{(k)}\left(\{h_{\Psi (v)}^{(k - 1)}:\Psi (v)\in \Phi \}\right)\right)}\\ & {\quad = \mathrm{Update}_{L}^{(k)}\left(h_{v}^{(k - 1)},h_{v - v}^{(k - 1)},\{h_{\Psi (v)}^{(k - 1)}:\Psi (v)\in \Phi \}\right),}\\ & {\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad s.t.v\in L} \end{array} \quad (3)\]  

Towards this principle, we observe that the embedding update of \(v\) in the current stage relies on the last- stage embeddings of \(v\) and its negation \(\neg v\) , and the embeddings of all the clauses that include \(v\) in a CNF formula \((\Psi (v) \in \Phi)\) . The literal \(v\) , \(\neg v\) and the clauses containing \(v\) are consistent over iterations. Hence if the update function (Eq. 3) is consistent over the iterations in Eq.2, i.e., \(\forall k \in \mathbb{N}_{+}\) , \(\mathrm{Update}_{L}^{(k)} = \mathrm{Update}_{L}\) , where \(\mathrm{Update}_{L}\) means the update for literal embedding, GNNs derived from Eq. 3 receive a fixed graph generated by a CNF formula as input. However, if a recursive algorithm iteratively changes the graph that represents a CNF formula, it implies that there must be a clause that was changed (or eliminated) after this iteration, since clauses are permutation- invariant in a CNF formula. Accordingly there must be a literal embedding whose update process depends on a clause different from the previous iteration. It contradicts the literal embedding update function learned by Eq. 3 with \(\forall k \in \mathbb{N}_{+}\) , \(\mathrm{Update}_{L}^{(k)} = \mathrm{Update}_{L}\) .  

Hence the message- passing in GNNs could not resemble the procedures in the complete SAT- solvers. In fact, GNNs are rather similar to learning a subfamily of incomplete SAT solvers (GSAT, WalkSAT [11]), which randomly assign variables and stochastically search for local witnesses.  

Observation 3.2. GNNs in Eq. 2 may simulate the local search in WalkSAT.  

Proof. Recall the iterative update routine of WalkSAT: starting by assigning a random value to each literal variable in a formula, it randomly chooses an unsatisfied clause in the formula and flips the value of a Boolean variable within that clause. Such process is repeated till the literal assignment satisfies all clauses in the formula. Here we construct the optimal aggregation and combine functions derived from Eq. 2, which are designed to simulate the procedure of WalkSAT. In this way, if the aggregation and combine functions in Eq. 2 approximate these optimal aggregation and combine functions, the GNN may simulate the local search in WalkSAT.  

Given a universe of literals in logical reasoning, we first initiate the embeddings of them and their negation, thus, \(\forall v \in L\) , random value of \(h_{v}^{(0)}\) and \(h_{\neg v}^{(0)}\) are initiated. This assignment can be treated as the Boolean value that belong to different literals, which have been mapped from a binary vector into a real- value embedding space about the literals. We also randomly initiate the clause embeddings \(h_{\Psi (v)}^{(0)}\) for reasoning each formula that contains the clause \(\Psi (v)\) . Here we define the optimal