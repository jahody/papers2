Here we elaborate how the four optimal functions above cooperate to simulate an iteration of Walk- SAT. Since GNNs use literal embeddings as the initial input, we first analyze Eq. 6 and takes a literal \(v\) into our consideration. As we discussed, this function receives a set of literal embeddings that denotes a clause that contains \(v\) , and then, takes the optimal Deep Sets as an oracle to judge whether this clause is satisfied. The output, the optimal message about the clause, equals to the initiated embedding of the clause \(h_{\Psi (v)}\) if it is satisfied, otherwise becomes 0. This process simulates the logical reasoning on a clause, which WalkSAT relies on to pick an unsatisfied clause and flip one of its variables (see Eq. 5). Based on \(m_{\Psi (v)}^{(k)}\) , the optimal clause combine function (Eq. 7) updates an arbitrary clause embedding that contains \(v\) . The first branch states that, if the current clause message \(m_{\Psi (v)}^{(k)}\) is consistent with the previous clause embedding \(h_{\Psi (v)}^{(k - 1)}\) , it implies the satisfiability of the clause \(\Psi (v)\) is not changed in this iteration (the previously satisfied clause is still satisfied, vice and versa). In this case the clause embedding would not be updated. The second and third branches imply that when \(m_{\Psi (v)}^{(k)}\) and \(h_{\Psi (v)}^{(k - 1)}\) are inconsistent, how to update the clause embedding \(h_{\Psi (v)}^{(k)}\) to convey the current message about whether the clause \(\Psi (v)\) is satisfied (return into the initial clause embeddings) or not (turn into 0). Therefore all updated embeddings about the clauses that contain \(v\) , as the neighbors of \(v\) , would be fed into the optimal aggregation function in Eq. 4. This function selects \(v\) that only exists in satisfied clauses, i.e., \(\prod_{\Psi (v)}||h_{\Psi (v)}^{(k)}||\neq 0\) (If there is an unsatisfied clauses, its embedding is 0 according to Eq. 7, and would lead to \(\prod_{\Psi (v)}||h_{\Psi (v)}^{(k)}|| = 0\) ), then the embedding of \(v\) would become 0. The results by this operation are taken advantage by Eq. 5, which promises the literal that only exists in satisfied clauses would not be "flipped" (WalkSAT only chooses unsatisfied clause and select its variables to flip. If literals are not in any unsatisfied clauses, it would not be chosen). Towards the literal \(v\) contained by one unsatisfied clause at least \((\prod_{\Psi (v)}||h_{\Psi (v)}^{(k)}|| = 0\) since there exists a clause embedding equals to 0 according to Eq. 7), its literal message would be assigned by a random vector \(\epsilon^{(k)}\) . It implies the randomness when WalkSAT try to select one of literal in unsatisfied clauses to flip its value. The flipping process is simulated by Eq. 6 as we have discussed.  

Here we further verify if a CNF formula could be satisfied, literal embeddings generated by the optimal aggregation and combine functions that represent the Boolean assignment of literal to satisfy this CNF formula, would converge over iterations (It corresponds to the stop criteria in Walk- SAT). Specifically suppose that in the \(k\) - 1 iteration, Eq. 5 have induced the literal embeddings so that all clauses with the literal in the formula have been satisfied. By Eq. 6 it is obvious that \(\forall v\in L\) , \(m_{\Psi (v)}^{(k)} = h_{\Psi (v)}^{(0)}\) . To this we have \(h_{\Psi (v)}^{(k - 1)} = m_{\Psi (v)}^{(k)}\) and \(h_{\Psi (v)}^{(k)} = h_{\Psi (v)}^{(k - 1)} = h_{\Psi (v)}^{(0)}\) since all clauses in the formula have already been satisfied before the current iteration. In this case, it holds \(\prod_{\Psi (v)}||h_{\Psi (v)}^{(k - 1)}||\neq 0\) and leads to \(\forall v\in L\) , \(m_{v}^{(k)} = 0\) in this formula (Eq. 4). In term of this, Eq. 5 guarantees all the literal embeddings consistent with those in the previous iteration.  

Concluding the analysis above, we know that the optimal aggregation and combine functions (Eq. 4 5 6 7 ) are cooperated to simulate the local search in WalkSAT.  

Failure in 2QBF. Notably the failure in proving UNSAT would not be a problem for GNNs applied to solve SAT, as predicting satisfiability with high confidence has already been good enough for a binary distinction. However, 2QBF problems imply solving UNSAT, which inevitably makes GNNs unavailable in proving the relevant formulae. It probably explains the mystery in[7] about why GNNs purely learned by data- driven supervised learning lead to the same performances as random speculation [16].  

## 4 Further Discussion  

In this manuscript, we provide some discussions about the GNNs that consider the SAT and 2QBF problem as static graph, we haven't considered the shrinkage condition, which may apply dynamic GNN as [9], dues to the difficulty about proving the dynamic graph as we need to prove all the dynamic updating methods are impossible or not. Ought to be regarded that, this manuscript does not claim GNN is provably unable to achieve UNSAT, which remains an open issue.