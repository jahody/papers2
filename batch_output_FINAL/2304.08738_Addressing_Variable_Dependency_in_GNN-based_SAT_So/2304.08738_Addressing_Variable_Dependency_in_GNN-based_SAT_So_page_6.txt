Table 2: Solution rate for the \(SR(n)\) problems   

<table><tr><td></td><td>SR(3)</td><td>SR(4)</td><td>SR(5)</td><td>SR(6)</td><td>SR(7)</td><td>SR(8)</td><td>SR(9)</td><td>SR(10)</td></tr><tr><td>AsymSAT</td><td>98.30%</td><td>100.00%</td><td>93.23%</td><td>94.51%</td><td>81.56%</td><td>82.90%</td><td>88.95%</td><td>85.45%</td></tr><tr><td>NeuroSAT</td><td>87.70%</td><td>74.47%</td><td>63.10%</td><td>59.57%</td><td>52.94%</td><td>48.40%</td><td>49.73%</td><td>43.82%</td></tr><tr><td>DG-DAGRNN</td><td>10.21%</td><td>15.23%</td><td>5.21%</td><td>1.83%</td><td>8.38%</td><td>5.70%</td><td>4.07%</td><td>4.24%</td></tr></table>  

Table 3: Solution rate for the \(V(n)\) problems   

<table><tr><td></td><td>V(3)</td><td>V(4)</td><td>V(5)</td><td>V(6)</td><td>V(7)</td><td>V(8)</td><td>V(9)</td><td>V(10)</td></tr><tr><td>AsymSAT</td><td>81.58%</td><td>67.50%</td><td>72.50%</td><td>55.50%</td><td>52.50%</td><td>60.00%</td><td>45.00%</td><td>47.50%</td></tr><tr><td>NeuroSAT</td><td>0.025%</td><td>0.00%</td><td>0.00%</td><td>0.00%</td><td>0.00%</td><td>0.00%</td><td>0.0%</td><td>0.00%</td></tr><tr><td>DG-DAGRNN</td><td>35.00%</td><td>47.50%</td><td>47.50%</td><td>45.00%</td><td>30.00%</td><td>37.50%</td><td>37.50%</td><td>32.50%</td></tr></table>  

figurations for our AsymSAT model: one uses LSTM and the other uses GRU in the bi- directional RNN layer (the \(\mathcal{R}\) layer). We also add one case of removing the \(\mathcal{R}\) layer in AsymSAT as comparison. In this experiment, we set the learning rate of AsymSAT models as \(10^{- 3}\) and the number of iterations as 5. Table 1 illustrates the result for the symmetric circuits on five different models. Just as we discussed in Section 3, DG- DAGRNN and NeuroSAT cannot break the tie in symmetric circuits or symmetric CNF formulas. And there is no way to train these two models on this dataset. Thanks to the \(\mathcal{R}\) layer we introduced, our AsymSAT model can reach a solution rate of \(100.00\%\) with either LSTM or GRU in the \(\mathcal{R}\) layer. This shows the effectiveness of the \(\mathcal{R}\) layer for symmetric circuits.  

Setting the number of iterations. In this experiment, we study the effect of changing the number of iterations on our network. We set the iteration to be 5, 10, 15, and 20, respectively, and test on a mixed dataset with instances from \(SR(3)\) to \(SR(10)\) . We can see for AsymSAT with GRU, increasing the number of iteration from 5 to 10 will greatly improve the accuracy, then the solving rate barely increases for more iterations. AsymSAT with LSTM shows a similar result, while it peaks at around 15 iterations. It seems that AsymSAT with LSTM may have a higher potential to achieve a better accuracy. Therefore, in the following experiments on SAT solving, we mainly use AsymSAT with LSTM for comparison.  

## Experiments for SAT solving  

In the following experiments, we compare the three models: our AsymSAT model with bi- directional LSTM in the \(\mathcal{R}\) layer, the NeuroSAT model, and the DG- DAGRNN model. We measure the performance using solution rate rather than the accuracy of predicting satisfiability. Solution rate is defined as the percentage of problems on which the network is able to predict one satisfying assignment.  

We admit that for different models, sometimes it is hard to make an absolutely fair comparison. As AsymSAT is supervised under the multi- bit SAT solution, whereas NeuroSAT is one- bit SAT/UNSAT supervision, AsymSAT is much more training- data- efficient and it can converge several orders of magnitude faster than NeuroSAT, although their parameter  

counts are roughly in the same scale (around 200K). Actually, the authors of NeuroSAT reported that it would take \(10^{7}\) SAT problems to train a full- fledged NeuroSAT [Selsam, 2018]. Although our training set is much smaller due to limitations of computing resources, we didn't observe the overfitting problem in the experiments judging from the training loss.  

Comparison on the \(SR(n)\) problems. We use \(8K\) \(SR(n)\) problems sampled uniformly from \(SR(U(3,8))\) to train the three models. The test set contains \(1.5K\) \(SR(n)\) problems \((n\) is from 3 to 10). For AsymSAT and DG- DAGRNN, CNF formulas are first converted into circuits to serve as the model input. Table 2 summarizes the performance measured on the \(SR(n)\) problem. The result shows that AsymSAT model has a better performance compared to NeuroSAT and DG- DAGRNN on this dataset. Overall, AsymSAT can reach more than \(90\%\) solution rate (averaged across \(SR(3)\) to \(SR(10)\) ), while NeuroSAT can only reach \(60\%\) . Furthermore, we supply more experimental results regarding larger \(SR(n)\) problems. When trained from \(SR(3)\) to \(SR(10)\) , AsymSAT outperforms NeuroSAT on \(SR(20)\) , \(SR(40)\) , \(SR(60)\) and \(SR(80)\) . The result is shown in Table 6. In our experiment, the performance of DG- DAGRNN is non- competitive to the other two. We conjecture that the unsupervised learning method in DG- DAGRNN suffers from the vanishing gradient problem if trained on circuits converted from CNF. We provide a detailed analysis of DG- DAGRNN in the appendix.  

Comparison on the \(V(n)\) problems. The training data is a mixture of \(8K\) \(SR(n)\) problems, \((n\) ranges from 3 to 10), and \(1.2K\) \(V(n)\) problems \((n\) ranges from 3 to 8). The test set is \(320\) \(V(n)\) problems \((n\) ranges from 3 to 10). Note that \(V(n)\) is a nontrivial dataset. On average, each \(V(10)\) problem has around 1K AND gates, more than those in circuits converted from the \(SR(10)\) problems (which each contain just about 200 AND gates). Even for the \(SR(40)\) problems, there are only approximately 600 - 800 AND gates per input. Therefore, \(V(n)\) problems can also demonstrate the generalization capability of the tested models. Although the indexing number \(n\) is relatively smaller in the \(V(n)\) dataset, there are plenty of logic gates in each circuit. These logic