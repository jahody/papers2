consist in a sample of formulae drawn from the benchmarks used to test the architecture. Our model is instead trained on a set of random formulae, which are very fast to obtain, and then eventually fine- tuned towards the specific test distribution. The architectural improvements guarantee a sensibly better performance in terms of scalability and generalizability than the BPNN model, as shown in Section B of the supplementary material. We believe that the attentional layer allows the network to focus on regions of the input formulae which are more significant for the #SAT problem.  

## 6 Conclusions  

We presented BPGAT, an extension of the BPNN architecture presented in [15], which combines the algorithmic structure of belief propagation and the learning paradigm of graph attention networks. We conducted several experiments to investigate the scalability and generalization abilities of our network, showing that it is able to achieve a performance comparable to (and in some settings higher than) state- of- the- art approximate #SAT solvers, albeit the lack of any theoretical guarantees on the quality of the solution. Finally, we highlighted the efficiency of our model, both in terms of required training data and in terms of running time.  

As future research directions, we will analyze the viability of extending our model to tackle weighted conjunctive normal form model counting (weighted #CNF) problems. In this scenario, a straightforward application of our model would be that of approximate probabilistic inference on Bayesian Networks, which in many cases (e.g. when solved using variational inference) comes without any statistical guarantees. It would be also interesting to generalize this approach to other counting problems, such as counting the number of independent sets of a given size in a graph, as part of a broader research program aiming at exploring the application of graph attention networks to logical reasoning tasks.  

## References  

1. Cnfgen: A generator of crafted benchmarks. In: Gaspers, S., Walsh, T. (eds.) Theory and Applications of Satisfiability Testing - SAT 2017 - 20th International Conference, Melbourne, VIC, Australia, August 28 - September 1, 2017, Proceedings. Lecture Notes in Computer Science, vol. 10491, pp. 464-473. Springer (2017). https://doi.org/10.1007/978-3-319-66263-3_30, https://doi.org/10.1007/978-3-319-66263-3_30  
2. Abboud, R., Ceylan, I.I., Lukasiewicz, T.: Learning to reason: Leveraging neural networks for approximate DNF counting. In: The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020. pp. 3097-3104. AAAI Press (2020), https://ojs.aaai.org/index.php/AAAI/article/view/5705  
3. Amizadeh, S., Matusevych, S., Weimer, M.: Learning to solve circuit-sat: An unsupervised differentiable approach. In: 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net (2019), https://openreview.net/forum?id=BJxgz2R9t7