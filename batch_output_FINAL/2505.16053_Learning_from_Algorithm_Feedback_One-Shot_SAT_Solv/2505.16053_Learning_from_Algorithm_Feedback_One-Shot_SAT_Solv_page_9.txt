<center>Figure 5: Weight correlation between policies learned with different solvers. For each instance distribution, we randomly sample 5,000 variables \(x\) from the corresponding validation set and plot the expected variable weight \(E[w(x)]\) for the policies learned with either base solver. The color further indicates the backbone or UNSAT core membership of each variable. </center>  

solvers. We further observe that for the 3CoL and CRYPTO instances, the variables with high weights are predominantly members of the UNSAT core. For these problem instances, the RLAF- based training therefore self- discovered weight policies that correlate to existing handcrafted heuristics while performing better, as demonstrated in Section 3.2. For the 3SAT instances, we do not observe a clear correlation between the learned weight policies and backbone membership, showing that in this case, the trained models express functions that, while effective, do not resemble this particular handcrafted heuristic.  

## 4 Discussion  

We introduced RLAF as a paradigm for training GNN- based policies that guide the branching heuristics of SAT solvers. Our work contributes (i) a generic mechanism for injecting variable weights into branching heuristics, (ii) a formulation of weight selection as a one- shot RL problem, (iii) a way to leverage GNNs as trainable policies in this setting, and (iv) experimental evidence that GRPO can learn policies that reduce the computational cost of different base solvers. In our empirical studies, the learned policies generalize to larger and harder instances, and consistently surpass supervised baselines that rely on handcrafted variable properties. Moreover, policies trained with different base solvers converge toward similar structural signals, suggesting that RLAF is capturing inherent information about SAT instance structure that is not specific to the underlying base solver.  

The current implementation is designed as a small- scale prototype optimized for training on relatively simple formulas using moderate hardware. This constraint allows for only comparatively simple problems to be solved quickly enough to collect sufficient solver feedback on local CPU cores in each GRPO iteration. Expanding the system to leverage distributed computing resources, such as cloud- based infrastructure, would enable the incorporation of larger and harder SAT problems during training, potentially leading to better guidance policies. GNN scalability also remains a bottleneck, particularly during training, as processing large industrial instances imposes significant memory and computational demands. Research into more compact, domain- specific graph encodings of CNFs remains important future work. At the same time, the expressive power of our network, a standard message- passing GNN, is bounded by color refinement (Morris et al., 2019; Xu et al., 2019), leaving highly symmetric patterns indistinguishable. Combining expressivity and scalability remains a critical challenge for applying GNNs to large, structured problem instances.  

Finally, the proposed methodology is not strictly limited to SAT solvers. Branching heuristics are critical components not only in SAT solving but also for Mixed- Integer Programming (MIPs) and Constraint Satisfaction Problems (CSPs). More broadly, implementing any kind of selection heuristic as the argmax of some scoring function is a generic pattern of algorithm design found across many domains. For any such algorithm, one can introduce external multiplicative weights that guide the heuristic and then phrase the task of inferring effective weights as an RL problem. In this work, we have demonstrated that this general methodology can be leveraged in the context of SAT solving. Translating it to other domains and algorithms remains as future work.