<center>Figure 2: Literal-clause graph representation of a SAT instance used in this work. The instance is converted to CNF form, and nodes represent positive literals, negative literals and clauses. Edges are drawn between clauses and literal nodes if the literal participate in the clause, and edges are also drawn between positive and negative nodes of the same variable. The nodes are endowed with feature vectors described in Appendix A. </center>  

To do so, at train- time, we are given a collection of SAT instances and for each instance \(a_{i}\) , we are given sampled solving times \(t_{i}^{1},\dots,t_{i}^{K}\) from each solver. This dataset can be used for training a machine learning model offline in a supervised manner. At test- time, a separate collection of SAT instances are given to the model, which selects a solver for each. The selected solver for each instance is run, and the average runtime over all testing instances is used to benchmark performance of the selector model.  

### 3.2 Representation and features  

The inputs to the model are individual SAT instances. We assume that they are formulated in conjunctive- normal form (CNF), that is as a formula \(c_{1}\wedge \dots \wedge c_{m}\) where each \(c_{i}\) is a clause, which in turn is in the form \(c_{i} = l_{1}\lor l_{2}\lor \ldots\) , where each literal \(l_{i}\) stands for a variable \(x_{j}\) in the problem, or its negation \(\bar{x}_{j}\) . Any SAT problem can be converted into an equivalent CNF problem in linear time [40].  

Given CNF SAT instances, we input them to the machine learning model as literal- clause graphs (LCGs) [19] endowed with extra information in the form of node features. A representation is provided in Figure 2. The literal- clause graph of a SAT instance is an undirected graph with three types of node: one node \(c_{j}\) per clause in the graph, and two nodes \(x_{i}\) and \(\bar{x}_{i}\) per variable in the graph, representing itself and its negation respectively. An edge is drawn between a clause node \(c_{j}\) and a variable node \(x_{i} / \bar{x}_{i}\) if the variable (respectively, its negation) appears as literal in the clause. Finally, an edge is drawn between every positive and negative variable node.  

In addition, to every clause node and variable node, we attach feature vectors. Most features are hand- designed and are inspired by those used by SATzilla [45, 47]. They represent expert knowledge that is known to be critical for SAT solving process, such as the presence of Horn clauses, which are clauses containing at most one positive literal. These are especially important for the solving process as the collection of Horn clauses can be proved within linear time [11]. Besides these hand- designed features, clause node features are also enriched with a positional encoding, described in the next subsection. A complete list of the features used is provided in Appendix A.   

3.2.1 Clause positional embeddings. In principle, satisfiability of a SAT formula is not affected by permuting the variables or clauses, and literal- clause graphs are permutation- invariant as well. In practice, however, we found solver runtimes can be sensitive to the order in which clauses are provided as input. We conducted a study with the popular Kissat 3.0 [3] solver on the industrial LEC dataset described further in Section 4. As can be seen in Figure 3, shuffling clauses sometimes led to very large variations in runtime. In contrast, shuffling variables showed limited impact.  

This is in line with previously reported remarks on other SAT solvers [12, 39]. A possible explanation could be the algorithmic design of modern solvers, for which the storage architecture of variables relies on a doubly linked list and the initial storage order follows the parsing order of the clauses. This results in variations in cache miss rates depending on the provided clause ordering. In contrast, variable ordering usually only impacts the variable labels used by the solvers.  

To address the sensitivity to clause ordering, we include positional encodings among the clause features. These encode the position of a clause within the CNF formula. We follow the classical encodings from Vaswani et al. [41] and endow the \(k^{\mathrm{th}}\) clause with a 10- dimensional embedding  

\[PE(k,2i) = \sin \left(\frac{k}{10000^{2i / 10}}\right),\] \[PE(k,2i + 1) = \cos \left(\frac{k}{10000^{2i / 10}}\right),\]  

where \(i = 0,\ldots ,4\) . This vector is concatenated with the rest of the clause node features.  

### 3.3 Model  

We use a graph neural network (GNN) model to predict which solver to use for a given instance. These models operate on graphs by repeatedly modifying node embeddings through graph convolution operations, and have emerged as a standard paradigm for dealing with graph- structured data, both in SAT solving [19] and more widely for combinatorial optimization in general [5]. However, we deviate from standard graph convolution frameworks by interpreting our literal- clause graph as a graph with three types of edges: (i) from clause to literal nodes; (ii) from literal to clauses nodes; and (iii) between positive and negative literal nodes. These graphs can then be interpreted as "heterogeneous graphs", and we can apply heterogenous GNN methodologies [50].  

In this framework, the graph convolution steps take the following edge- type- dependent form. Let \(x_{j}\in \mathbb{R}^{d}\) stand for the feature vector at node \(j\) . For every edge \((j,i)\in \mathcal{E}_{k}\) of type \(k\in \{1,\ldots ,K\}\) from node \(j\) to node \(i\) , we compute a message \(m_{i,j,k} = \phi_{k}(x_{i},x_{j})\) where \(\phi_{k}\) is a learnable "message function". We then update the feature vector at node \(i\) by the formula  

\[\overline{m}_{i,k} = \rho_{k}\big(\{m_{i,j,k}\mid (j,i)\in \mathcal{E}_{k}\} \big),\] \[x_{i}\leftarrow \delta \Big(\Big\{\psi_{k}(x_{i},\overline{m}_{i,k})\Big|k = 1\ldots ,K\Big\} \Big),\]