prediction, we evaluate both NeuroSAT and GGNN using multiple- prediction decoding. Our evaluation focuses on three key aspects: (a) the number of distinct predicted assignments, (b) the number of flipped variables between two consecutive iterations, and (c) the number of unsatisfiable clauses associated with the predicted assignments.  

<center>Figure 5: Results on the predicted assignments with the increased message passing iteration \(T\) . NeuroSAT\* refers to the model trained for satisfiability prediction. </center>  

As shown in Figure 5, all three GNN models initially generate a wide array of assignment predictions by flipping a considerable number of variables, resulting in a notable reduction in the number of unsatisfiable clauses. However, as the iterations progress, the number of flipped variables diminishes substantially, and most GNN models eventually converge towards predicting a specific assignment or making minimal changes to their predictions when there are no or very few unsatisfiable clauses remaining. This trend is reminiscent of the greedy solving strategy adopted by the LS solver GSAT (Selman et al., 1992), where changes are made to minimize the number of unsatisfied clauses in the new assignment. However, unlike GSAT's approach of flipping one variable at a time and incorporating random selection to break ties, GNN models simultaneously modify multiple variables and potentially converge to a particular unsatisfied assignment and find it challenging to deviate from such a prediction. It is also noteworthy that despite being trained for satisfiability prediction, NeuroSAT\* demonstrates similar behavior to the GNN models trained for assignment prediction. This observation indicates that GNNs also learn to search for a satisfying assignment implicitly in the latent space while performing satisfiability prediction. To provide more insights into the strengths and limitations of GNN- based heuristics, we further conduct experiments to compare GNN- based SAT solvers against state- of- the- art CDCL and LS- based SAT solvers in Appendix D.2.  

## 7 Discussions  

### 7.1 Limitations and Future Work  

While G4SATBench represents a significant step in evaluating GNNs for SAT solving, there are still some limitations and potential future directions to consider. Firstly, G4SATBench primarily focuses on evaluating standalone neural SAT solvers, excluding the exploration of neural- guided SAT solvers that integrate GNNs with search- based SAT solvers. It also should be emphasized that the instances included in G4SATBench are considerably smaller compared to most practical instances found in real- world applications, where GNN models alone are not sufficient for solving such large- scale instances. The efficacy of GNN models in unsat- core prediction shows a promising avenue for combining GNNs with modern SAT solvers, and future research could explore more techniques to effectively leverage these neural- guided SAT solvers to scale up to real- world instances. Secondly, G4SATBench benchmarks general GNN models on the LCG\* and VCG\* graph representations for SAT solving, but does not consider sophisticated GNN models designed for specific graph constructions in certain domains, such as Circuit SAT problems. Investigating domain- specific GNN models tailored to the characteristics of specific problems could lead to improved performance in specialized instances. Lastly, all existing GNN- based SAT solvers in the literature are static GNNs, which have limited learning ability to capture the CDCL heuristic. Exploring dynamic GNN models that can effectively learn the CDCL heuristic is also a potential direction for future research.