Here, \(\mathbb{1}_{[k \neq i]}\) is an indicator function that evaluates to 1 if \(k \neq i\) , \(\tau\) is a temperature parameter, and \(\text{sim}(\cdot , \cdot)\) is the similarity function defined as \(\text{sim}(m_i, m_j) = m_i^\top m_j / \|m_i\| \|m_j\|\) . The final loss is the average over all positive pairs. In our experiments, we set the temperature parameter to 0.5 and utilize a learning rate of \(10^{- 4}\) with a weight decay of \(10^{- 8}\) . The pretraining process is performed for a total of 100 epochs. Once the pretraining is completed, we keep the GNN model and remove the projection head for downstream tasks.  

For experiments involving random initialization, we utilize Kaiming Initialization (He et al., 2015) to initialize all literal/variable and clause embeddings during both training and testing. For the predicted assignments, we utilize 2- clustering decoding to construct two possible assignment predictions for NeuroSAT\* at each iteration. When calculating the number of flipped variables and unsatisfiable clauses for NeuroSAT\*, we only consider the better assignment prediction of the two at each iteration, which is the one that satisfies more clauses. All other experimental settings remain the same as in the benchmarking evaluation.  

## D.2 Comparisons with State-of-the-art SAT Solvers  

We compare NeuroSAT with two advanced CDCL and LS solvers, CaDiCaL Fleury & Heisinger (2020) and Sparrow (Balint & Fr√∂hlich, 2010). To enable a fair comparison, we first configure Sparrow to generate the same number of assignments as NeuroSAT by setting its maximum flip number to 32, allowing for an apples- to- apples comparison of both solvers' accuracy and execution time. Subsequently, we allow Sparrow and CaDiCaL to run without constraints to solve the satisfiable instances in G4SATBench. Considering that NeuroSAT processes a batch of problems in parallel on GPUs, we calculate its per- instance runtime by dividing the total execution time by the number of testing instances.  

The results, summarized in Table 12, indicate that GNN- based heuristics could outperform modern local search solvers like Sparrow, generating more satisfying assignments extremely fast when constrained to output a limited number of solutions. However, once such a constraint is lifted, both Sparrow and CaDiCaL can traverse the solution space efficiently and solve all satisfiable instances in G4SATBench, while GNN models like NeuroSAT may find it challenging due to their limited exploration capacity as evidenced in Figure 5a. Nevertheless, it's crucial to recognize that while GNN models are hard to compete with CaDiCaL and Sparrow, their assignment predictions could still serve as good initializations in these solvers, potentially leading to better performance (Zhang et al., 2020; Li & Si, 2022).  

Table 12: Results of NeuroSAT, Sparrow, and CaDiCaL. The top 2 rows represent the solving accuracy (%), and the bottom 4 rows represent the running time (second) per instance. Sparrow\\* refers to Sparrow limited to a maximum of 32 flips.   

<table><tr><td rowspan="2">Method</td><td colspan="7">Easy Datasets</td><td colspan="7">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td>NeuroSAT</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.461</td><td>70.83</td><td>71.03</td><td>32.48</td><td>96.18</td><td>95.99</td></tr><tr><td>Sparrow*</td><td>56.03</td><td>52.09</td><td>85.48</td><td>77.25</td><td>53.68</td><td>37.15</td><td>31.61</td><td>1.64</td><td>1.85</td><td>12.68</td><td>10.72</td><td>12.99</td><td>1.27</td><td>0.53</td></tr><tr><td>NeuroSAT</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.003</td><td>0.002</td><td>0.003</td><td>0.008</td><td>0.006</td><td>0.009</td><td>0.010</td><td>0.009</td><td>0.006</td><td>0.007</td></tr><tr><td>Sparrow*</td><td>0.005</td><td>0.005</td><td>0.006</td><td>0.006</td><td>0.005</td><td>0.005</td><td>0.005</td><td>0.008</td><td>0.007</td><td>0.006</td><td>0.006</td><td>0.006</td><td>0.007</td><td>0.006</td></tr><tr><td>Sparrow</td><td>0.007</td><td>0.007</td><td>0.008</td><td>0.008</td><td>0.007</td><td>0.009</td><td>0.009</td><td>0.013</td><td>0.013</td><td>0.010</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td></tr><tr><td>CaDiCaL</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.043</td><td>0.016</td><td>0.018</td><td>0.015</td><td>0.013</td><td>0.012</td></tr></table>