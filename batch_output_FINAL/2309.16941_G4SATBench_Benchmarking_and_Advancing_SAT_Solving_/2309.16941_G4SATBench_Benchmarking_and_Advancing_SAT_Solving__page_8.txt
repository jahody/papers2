Table 2: Solving accuracy on identical distribution with different training losses. SUP denotes the supervised loss, \(\mathrm{UNS}_1\) and \(\mathrm{UNS}_2\) correspond to the unsupervised losses defined in Equation 5 and Equation 6, respectively. The symbol "-" indicates that some seeds failed during training. Note that only satisfiable instances are evaluated in this experiment.   

<table><tr><td rowspan="2">Graph</td><td rowspan="2">Method</td><td rowspan="2">Loss</td><td colspan="6">Easy Datasets</td><td colspan="6">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td></tr><tr><td rowspan="3">LCG*</td><td rowspan="3">NeuroSAT</td><td>SUP</td><td>88.47</td><td>78.39</td><td>0.27</td><td>39.18</td><td>66.30</td><td>69.61</td><td>85.15</td><td>34.97</td><td>20.07</td><td>0.00</td><td>3.64</td><td>56.61</td><td>52.09</td></tr><tr><td>UNS1</td><td>82.30</td><td>80.23</td><td>82.17</td><td>89.23</td><td>88.34</td><td>96.74</td><td>99.36</td><td>25.00</td><td>30.40</td><td>35.45</td><td>60.28</td><td>41.45</td><td>95.06</td></tr><tr><td>UNS2</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.61</td><td>70.83</td><td>71.03</td><td>-</td><td>96.18</td><td>95.99</td></tr><tr><td rowspan="3">VCG*</td><td rowspan="3">GGNN</td><td>SUP</td><td>84.13</td><td>72.87</td><td>0.29</td><td>38.82</td><td>60.80</td><td>68.36</td><td>82.06</td><td>14.15</td><td>7.96</td><td>0.00</td><td>2.33</td><td>52.35</td><td>49.07</td></tr><tr><td>UNS1</td><td>76.39</td><td>76.55</td><td>78.13</td><td>84.44</td><td>84.60</td><td>97.49</td><td>-</td><td>16.55</td><td>22.84</td><td>28.12</td><td>44.89</td><td>54.29</td><td>-</td></tr><tr><td>UNS2</td><td>78.75</td><td>76.42</td><td>84.08</td><td>86.29</td><td>87.12</td><td>98.06</td><td>99.34</td><td>21.18</td><td>25.68</td><td>50.66</td><td>57.96</td><td>68.91</td><td>92.26</td><td>94.30</td></tr></table>  

### 5.3 Unsat-core Variable Prediction  

Evaluation on the same distribution. The benchmarking results presented in Table 3 exhibit the superior performance of all GNN models on both easy and medium datasets, with NeuroSAT consistently achieving the best results across most datasets. It is important to note that the primary objective of predicting unsat- core variables is not to solve SAT problems directly but to provide valuable guidance for enhancing the backtracking search process. As such, even imperfect predictions - for instance, those with a classification accuracy of \(90\%\) - have been demonstrated to be sufficiently effective in improving the search heuristics employed by modern CDCL- based SAT solvers, as indicated by previous studies (Selsam & Bj√∏rner, 2019; Wang et al., 2021).  

Table 3: Classification accuracy of unsat-core variables on identical distribution. Only unsatisfiable instances are evaluated.   

<table><tr><td rowspan="2">Graph</td><td rowspan="2">Method</td><td colspan="6">Easy Datasets</td><td colspan="6">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td rowspan="4">LCG*</td><td>NeuroSAT</td><td>90.76</td><td>94.43</td><td>83.69</td><td>86.20</td><td>99.93</td><td>95.80</td><td>94.47</td><td>90.07</td><td>99.65</td><td>85.73</td><td>88.53</td><td>99.97</td><td>97.90</td></tr><tr><td>GCN</td><td>89.17</td><td>94.35</td><td>82.89</td><td>85.32</td><td>99.93</td><td>95.74</td><td>94.43</td><td>88.11</td><td>99.65</td><td>85.71</td><td>87.70</td><td>99.96</td><td>97.89</td></tr><tr><td>GGNN</td><td>90.02</td><td>94.38</td><td>83.59</td><td>86.03</td><td>99.93</td><td>95.79</td><td>94.46</td><td>89.05</td><td>99.65</td><td>85.69</td><td>87.95</td><td>99.96</td><td>97.89</td></tr><tr><td>GIN</td><td>89.29</td><td>94.33</td><td>83.71</td><td>85.97</td><td>99.93</td><td>95.81</td><td>94.47</td><td>88.85</td><td>99.65</td><td>85.71</td><td>87.92</td><td>99.96</td><td>97.89</td></tr><tr><td rowspan="3">VCG*</td><td>GCN</td><td>88.57</td><td>94.34</td><td>83.17</td><td>85.27</td><td>99.93</td><td>95.79</td><td>94.46</td><td>88.17</td><td>99.65</td><td>85.70</td><td>87.37</td><td>99.96</td><td>97.90</td></tr><tr><td>GGNN</td><td>89.57</td><td>94.37</td><td>83.50</td><td>85.84</td><td>99.93</td><td>95.81</td><td>94.49</td><td>88.84</td><td>99.65</td><td>85.68</td><td>88.03</td><td>99.98</td><td>97.90</td></tr><tr><td>GIN</td><td>89.50</td><td>94.35</td><td>83.23</td><td>85.69</td><td>99.93</td><td>95.79</td><td>94.47</td><td>89.51</td><td>99.65</td><td>85.72</td><td>88.13</td><td>99.96</td><td>97.89</td></tr></table>  

We also conduct experiments to evaluate the generalization ability of GNN models on unsat- core variable prediction. Please see appendix C.4 for details.  

## 6 Advancing Evaluation on G4SATBench  

To gain deeper insights into how GNNs tackle the SAT problem, we conduct comprehensive comparative analyses between GNN- based SAT solvers and the CDCL and LS heuristics in this section. Since these search heuristics aim to solve a SAT instance directly, our focus only lies on the tasks of (T1) satisfiability prediction and (T2) satisfying assignment prediction (with \(\mathrm{UNS}_2\) as the training loss). We employ NeuroSAT (on \(\mathrm{LCG}^*\) ) and GGNN (on \(\mathrm{VCG}^*\) ) as our GNN models and experiment on the SR and 3- SAT datasets. Detailed experimental settings are included in Appendix D.1.  

### 6.1 Comparison with the CDCL Heuristic  

Evaluation on the clause- learning augmented instances. CDCL- based SAT solvers enhance backtracking search with conflict analysis and clause learning, enabling efficient exploration of the search space by iteratively adding "learned clauses" to avoid similar conflicts in future searches (Silva & Sakallah, 1999). To assess whether GNN- based SAT solvers can learn and benefit from the backtracking search (with CDCL) heuristic, we augment the original formulas in the datasets with learned clauses and evaluate GNN models on these clause- augmented instances.