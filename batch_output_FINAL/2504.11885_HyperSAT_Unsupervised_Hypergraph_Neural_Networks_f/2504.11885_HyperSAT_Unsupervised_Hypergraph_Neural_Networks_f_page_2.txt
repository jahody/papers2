The neural- guided solvers, on the other hand, integrate neural networks with traditional search frameworks to improve both the efficiency and solution quality of SAT solvers. Along this line, NeuroCore (Selsam & Bj√∏rner, 2019) leveraged Graph Neural Networks (GNNs) to predict unsatisfiable cores in SAT instances and further applied this prediction to periodically update the activity score of each variable in the Conflict- Driven Clause Learning (CDCL) solver. NLocalSAT (Zhang et al., 2021) employed a gated graph convolutional network (GGCN) to guide the initialization of assignments in the Stochastic Local Search (SLS) solver. Recently, NeuroBack (Wang et al., 2024) proposed a new approach by utilizing a graph transformer architecture to make offline neural predictions on backbone variable phases for refining the phase selection heuristic in CDCL solvers.  

For the MaxSAT problem, (Liu et al., 2023) was the pioneering work in exploring the use of GNNs for solving the MaxSAT problem. This work represented the MaxSAT problem as two kinds of factor graphs and studied the capability of typical GNN models in solving the MaxSAT problem from a theoretical perspective. Overall, it can be observed that GNNs have shown promising performance in solving both SAT and MaxSAT problems, however, the extension of these methods to the Weighted MaxSAT problem remains underdeveloped to our best knowledge. The main challenge comes from the uneven weight distribution in the Weighted MaxSAT problem. The addition of weights increases the complexity of the search space and also makes the design of effective heuristics more difficult. The neural model needs to learn how to prioritize high- weight clauses over others. Moreover, since a small change in the assignment could result in a significant change in the weighted sum, the hidden structural patterns within Weighted MaxSAT instances are much harder to learn.  

In this work, we consider the problem of designing a neural network solver for Weighted MaxSAT problems. Considering the intrinsic difficulties in learning the non- linear dependency and sensitive objective function in the Weighted MaxSAT problem, we formulate our learning- based framework HyperSAT by integrating hypergraph representation, cross- attention mechanism, and multi- objective loss design. We model the Weighted MaxSAT instance as a hypergraph. The positive and negative literals of a variable are represented as separate nodes, and each clause is represented as a hyperedge, with an associated weight equal to the weight of the clause. The hypergraph convolutional network (HyperGCN) is utilized as the learning model, and a specific cross- attention mechanism is designed to capture the logical interplay between the positive and negative literal node features of the same variable. In addition, we design an unsupervised multi- objective loss function to optimize the learning model. Besides the intrinsic optimization objective of the Weighted MaxSAT problem, a shared representation constraint ob  

jective is introduced to ensure that the representations of positive and negative literals of a variable are as distinct as possible in the feature space. We have tested our model on several random Weighted MaxSAT datasets in different settings. The experimental results demonstrate that our model outperforms baseline methods across various datasets, achieving significantly better performance. This work provides a new perspective on solving the Weighted MaxSAT problem using learning- based methods, with the hope that the results can offer preliminary knowledge into the capability of neural networks for solving Weighted MaxSAT problems in the future.  

In summary, we make the following contributions:  

- We propose HyperSAT, an innovative neural approach that uses an unsupervised hypergraph neural network model to solve Weighted MaxSAT problems. This is the first work to predict the solution of the Weighted MaxSAT problem with HyperGCN in an end-to-end fashion.- We propose a hypergraph representation for Weighted MaxSAT instances and design a cross-attention mechanism along with a shared representation constraint loss function to capture the logical relationships between positive and negative literal nodes within the hypergraph.- We conduct an extensive evaluation of the proposed HyperSAT on multiple Weighted MaxSAT datasets with different distributions. The experimental results demonstrate the superior performance of HyperSAT.  

## 2. Preliminaries  

We now briefly introduce some relevant preliminaries on Weighted MaxSAT and hypergraph neural networks that will be leveraged in later sections.  

### 2.1. Weighted MaxSAT  

A Weighted MaxSAT instance is represented by a triple \(\phi = (\mathcal{X}, \mathcal{C}, \mathbf{w})\) . Here, the set of variables is denoted by \(\mathcal{X} = \{x_1, x_2, \ldots , x_n\}\) , where each \(x_i \in \{0, 1\}\) is a Boolean variable and \(n\) is the total number of variables involved in the instance. The set of clauses is given by \(\mathcal{C} = \{C_1, C_2, \ldots , C_m\}\) , where each \(C_j \in \mathcal{C}\) is a disjunction of literals and \(m\) is the number of clauses. The weight vector is given by \(\mathbf{w} = (w_1, w_2, \ldots , w_m)\) where \(w_j\) represents the weight of \(C_j\) . Take the clause \(C_j \in \mathcal{C}\) for example. Suppose it contains \(k_j\) literals. Then, it can be represented by \(C_j = l_{j1} \lor l_{j2} \lor \dots \lor l_{jk_j}\) , where each literal \(l_{ji}\) is either a variable or the negation of a variable in \(\mathcal{X}\) . The clause \(C_j\) is satisfied if at least one of its literals evaluates to true. The clause \(C_j\) is unsatisfied if all its literals evaluate to false.