# On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature  

Geri Skenderi  Bocconi Institute for Data Science and Analytics  Bocconi University  geri.skenderi@unibocconi.it  

## Abstract  

Graph Neural Networks (GNNs) have recently shown promise as solvers for Boolean Satisfiability Problems (SATs) by operating on graph representations of logical formulas. However, their performance degrades sharply on harder instances, raising the question of whether this reflects fundamental architectural limitations. In this work, we provide a geometric explanation through the lens of graph Ricci Curvature (RC), which quantifies local connectivity bottlenecks. We prove that bipartite graphs derived from random \(k\) - SAT formulas are inherently negatively curved, and that this curvature decreases with instance difficulty. Building on this, we show that GNN- based SAT solvers are affected by oversquashing, a phenomenon where long- range dependencies become impossible to compress into fixed- length representations. We validate our claims empirically across different SAT benchmarks and confirm that curvature is both a strong indicator of problem complexity and can be used to predict performance. Finally, we connect our findings to design principles of existing solvers and outline promising directions for future work.  

## 1 Introduction  

The Boolean Satisfiability Problem (SAT) is a cornerstone problem of theoretical computer science. It can be succinctly described as the problem of proving logical formulas. Such a problem can consist in making a decision (is the formula satisfiable) or providing an assignment (what is the bitstring that satisfies the formula). SAT plays a foundational role in complexity theory as the first NP- Complete problem[13]. Furthermore, many other combinatorial optimization problems such as matching, routing, and covering can be reduced to SAT [24], which provides a way to characterize the hardness of these problems. Secondly, many real- world tasks such as circuit verification, automated planning, and software testing, are routinely cast into SAT form [31] and solved by optimized algorithms [6, 7]. Beyond computer science, a large body of work in the field of statistical physics has both studied typical- case theoretical properties [26, 36, 50] and proposed various solvers [2, 8, 30].  

Recently, Graph Neural Networks (GNNs) [20, 45] have emerged as a new competitor in combinatorial problem solving by learning over the graph representations of these problems [10]. This tendency has also extended to learning GNNs- based SAT solvers [12, 19, 40, 46]. By representing logical formulas as bipartite graphs that connect variables to clauses, GNNs can be trained end- to- end on both decision and assignment scenarios. Nevertheless, despite their flexibility, these neural solvers remain fragile in practice. Their performance deteriorates on problems that are anecdotally or formally known to be of increasing (algorithmic) difficulty, e.g., larger \(k\) values in random \(k\) - SAT [28, 33].  

Numerous studies have shown that GNNs suffer from two prevalent feature learning issues given the input data structure: oversmoothing [27] and oversquashing [1]. Oversmoothing refers to the idea that repeated aggregation causes node representations to become increasingly similar, eventually making them indistinguishable. This effect often imposes a practical upper bound on GNN depth. Oversquashing occurs when information from an exponentially expanding neighborhood must be