## 5 Related Works  

Since #SAT was proven to be a #P- complete problem, developing efficient solutions for #SAT with limited computational resources has become a key research focus. Traditional model counting methods are categorized into two groups based on the required accuracy of results: exact counting and approximate counting. Recent advances have also introduced data- driven neural network approaches, which leverage learning capabilities to address #SAT's inherent complexity.  

Exact counting methods prioritize absolute correctness of results, making them suitable for scenarios with small variable scales or specialized formula structures. They can be further divided into search- based and dynamic programming (DP)- based approaches, depending on their core reasoning mechanisms. Search- based methods typically extend the Davis- Putnam- Logemann- Loveland (DPLL) algorithm—an iterative search procedure for propositional satisfiability—to count satisfying assignments. While these methods guarantee exact results, their scalability is sometimes limited due to exponential time complexity in the worst case. Well known tools in the search- based category includes c2d [10], SharpSAT [32], D4 [19], Ganak [29], ExactMC [20], Panini [22], etc. DP- based exact counters avoid brute- force search by decomposing the formula into subproblems and solving them recursively. Two representative methods are ADDMC [13] and DPMC [14].  

Approximate counting methods trade off result accuracy for polynomial- time complexity, addressing the scalability gap of exact methods for large- scale CNF formulas. The most mainstream approaches in this category are hash- based approximate counters, which rely on randomization to estimate model counts without exhaustive enumeration. The core idea of hash- based methods is to partition the solution space (all variable assignments) into disjoint, uniformly sized "cells" using random hash functions. The total number of models is then estimated by: (1) randomly selecting a cell; (2) exactly counting the number of satisfying assignments within that cell; and (3) scaling the count by the total number of cells. A pioneering and widely used solver in this area is ApproxMC [6] and its subsequent optimizations [7, 31, 30, 36]. ApproxMC introduces random XOR constraints to partition the solution space—each XOR constraint defines a hash function that groups assignments into cells. It provides provable approximation guarantees by controlling the number of XOR constraints and the number of sampled cells. However, ApproxMC's performance heavily depends on the efficiency of its underlying SAT solver (used to count assignments in sampled cells) and requires careful engineering for state management and solver interaction. While ApproxMC provide guaranteed approximation, there are also some efficient approximate model counters without guarantee, such as STS [15], sats [17], and PartialKC [21].  

With the rise of deep learning, data- driven neural network approaches have emerged as a new paradigm for #SAT, leveraging graph neural networks (GNNs) and message- passing architectures to learn patterns from formula structures. These methods do not rely on handcrafted heuristics, making them more adaptable to diverse formula distributions. Early works focused on predicting satis