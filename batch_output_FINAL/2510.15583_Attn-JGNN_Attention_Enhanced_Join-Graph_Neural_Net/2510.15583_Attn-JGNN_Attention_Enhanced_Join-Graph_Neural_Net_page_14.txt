fiability (SAT) rather than counting models. A foundational example is NeuroSAT [28], which uses a GNN to perform message passing on a variable- clause bipartite graph (nodes represent variables/ clauses, edges represent membership). NeuroSAT learns to classify formulas as satisfiable or unsatisfiable by updating node features through iterative message exchangeâ€”demonstrating that neural networks can capture logical dependencies without explicit rule- based reasoning. Recent works extend neural approaches to #SAT by integrating message- passing algorithms (e.g., belief propagation) with neural networks, Proposed by Kuck et al., BPNN [18] combines belief propagation (BP) with a neural network architecture. It frames model counting as a probabilistic inference problem and uses BP to propagate beliefs (assignment probabilities) in the latent space. BPNN achieves up to 100x faster counting than state- of- the- art handcrafted solvers for certain formula classes, though it relies on BP's limitations (e.g., inaccuracy on cyclic graphs). Developed by Averi et al., BPGAT [27] extends BPNN by introducing an attention mechanism. It assigns higher weights to critical variables and clauses, enhancing the model's ability to capture impactful logical constraints. BPGAT serves as an approximate model counter, improving accuracy over BPNN but suffering from high computational overhead due to global attention.  

## 6 Conclusions  

In this work, we propose a neural framework for solving the satisfiability problem. Our framework combines tree decomposition and GAT, includes IJGP in the latent space, and performs partition function estimation to solve #SAT. Experimental evaluation on synthetic datasets and existing benchmarks shows that our approach significantly outperforms NSNet and other neural baselines and achieves competitive results compared to state- of- the- art solvers.  

Acknowledgments. This work was supported in part by Jilin Provincial Natural Science Foundation [20240101378JC], Jilin Provincial Education Department Research Project [JJKH20241286KJ], and the National Natural Science Foundation of China [U22A2098, 62172185, and 61976050]  

## References  

1. Dimitris Achlioptas, Zayd Hammoudeh, and Panos Theodoropoulos. Fast and flexible probabilistic model counting. In Olaf Beyersdorff and Christoph M. Wintersteiger, editors, Theory and Applications of Satisfiability Testing - SAT 2018 - 21st International Conference, SAT 2018, Held as Part of the Federated Logic Conference, FloC 2018, Oxford, UK, July 9-12, 2018, Proceedings, volume 10929 of Lecture Notes in Computer Science, pages 148-164. Springer, 2018.  
2. Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve circuit-sat: An unsupervised differentiable approach. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019.