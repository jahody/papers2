learning the approximate values of the partition function in statistical physics as an approximate #SAT solver. This general network framework usually relies on propagation algorithms such as belief propagation algorithms. When the propagation algorithm converges, it corresponds to the critical point of Bethe free energy. The iterative process of the propagation algorithm is the process of finding the extreme point of bethe free energy [8]. Our work is based on this framework.  

A recent work, NSNet [23], a general graph neural network framework, describes the satisibility problem as a probabilistic reasoning problem on the graph, relying only on simple belief propagation (BP) as the message update rule in the latent space, and estimates the partition function to complete the approximate prediction. Encouraging results were shown on the #SAT question. However, although the BP algorithm is accurate in the tree structure, it inevitably generates repetitive messages when facing complex loop structures, resulting in NSNet being able to handle only specific graph structures and the solution accuracy being limited by the BP algorithm.  

Another kind of approximate model counter BPGAT [27] by extending the BPNN architecture [18], by introducing mechanism of attention, give important variables or higher weights of clause, Thereby improving the accuracy of understanding. However, due to the huge overhead brought by the global attention mechanism, it has not shown a very good effect on large- scale tasks, which is also limited by the graph structure.  

To solve the above problems, this paper proposes to use the Iterative join- graph Propagation (IJGP) [11] algorithm combined with the attention mechanism [5, 37] to solve the #SAT problem, which is called Attention Enhanced Join- Graph Propagation (Attn- JGNN). The IJGP algorithm is an approximate reasoning algorithm for probabilistic graphical models (such as Bayesian networks and Markov networks), aiming to effectively calculate the marginal probability or conditional probability of variables. The key idea is to approximate the precise solution by constructing a simplified join- graph and iteratively passing local messages. Compared with BP, IJGP can flexibly control the structure of the graph and the message- passing strategy by controlling the tree width of tree decomposition.  

We put the relevant variables and clause nodes into a clustering structure, connect different clusters through marked edges to form a join- graph, and apply the attention mechanism in each cluster of the join- graph to achieve a hierarchical effect. The Attn- JGNN model parameterizes the IJGP in the latent space through GNN and simulates its message update using the attention mechanism. IJGP avoids the repeated transmission of messages on the ring through edge marking, and its unique tree decomposition structure also enables us to better introduce the attention mechanism, thereby reducing the time complexity by an order of magnitude. Finally, similar to the previous framework, learn the partition function to approximately estimate the number of models.  

Specifically, in view of the hierarchical structure differences in message passing within and between clusters, we adopt a hierarchical structure where two