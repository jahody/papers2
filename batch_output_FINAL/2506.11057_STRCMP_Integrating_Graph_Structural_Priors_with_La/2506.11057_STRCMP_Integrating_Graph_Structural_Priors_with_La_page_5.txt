As shown in the leftmost part of Figure 2, we continue to use this technique to extract structure embedding of given CO problem, benefiting the following algorithm discovery process.  

Specifically, a bipartite graph \(G = (C,E,V)\) is constructed for the CO problem instance \(q\) , where \(C\) corresponds to the constraints of \(q\) ; \(V\) denotes the variables of \(q\) ; and an edge \(e_{ij} \in E\) between a constraint node \(i\) and a variable node \(j\) if they have a connection. A graph neural network \(\theta_{G}\) takes as input the bipartite graph to generate the structural embedding \(h_{q} \in \mathbb{R}^{d}\) of the problem instance \(q\) . We simply train \(\theta_{G}\) via a classification task, where a group of CO problems and their class label are given. The problems falling into the same class means that they originates from the same scenario/domain, such as traveling salesman problems [34], production planning [35], vehicle routing problem [36], etc. The data representation, training, implementation details are left to Appendix B.1. In this way, GNNs can capture structure priors of CO problem (such as symmetry, sparsity, and degeneracy), which are critical for solver decisions. The extracted embeddings transfers structural insights to downstream code generation task, facilitating generalization across problem classes.  

\(\bullet\) Structure- Aware Code Generation. In this step, we construct a composite generative model to achieve structure- aware algorithm discovery for CO problem. The composite model is essentially a concatenation of a GNN and an LLM. GNN is obtained via training method mentioned in Step \(\bullet\) and frozen in the composite model, which provides the structure embedding of given CO problem to LLM. The LLM takes as input the natural language description of the problem and of the code generation task. Then the LLM generates candidate algorithm in the form of code snippet conditioned on the natural language description and structure embedding for a specific solver, as shown in the middle part of Figure 2. The code generation procedure can be formulated below:  

\[P(w_{1},w_{2},\dots,w_{T}) = \prod_{t = 1}^{T}P_{\theta_{L}}(w_{t}|w_{< t};h_{q},N L), \quad (3)\]  

where \(\{w_{i}|i = 1,\dots,T\}\) is the code snippet predicted by the composite model; \(h_{q}\) is the structure embedding of given CO problem instance \(q\) ; \(N L\) is the natural language description of \(q\) and of code generation task; \(\theta_{L}\) is the parameter of LLM.  

As anticipated, the composite model exhibits suboptimal performance on code generation tasks for CO problems due to architectural incompatibilities that disrupt the native token prediction mechanism of the underlying LLM. To address this architectural mismatch, we implement a two- phase training protocol consisting of: (a) data curation through systematic problem sampling, and (b) parameter optimization via post- training. This phased approach enables effective adaptation of the composite architecture while preserving the structural integrity of the original CO problem representations.  

(a) Data Curation. To facilitate the post-training phase, we aim to collect four key categories of data: 1) mathematical formulations of CO problems; 2) natural language specifications detailing problem requirements alongside corresponding code generation objectives for targeted CO solvers; 3) executable code implementations derived from these specifications; and 4) quantitative performance metrics evaluating solution quality and computational efficiency of the implemented code.  

(b) Post-Training. In this phase, we only train the parameter \(\theta_{L}\) of the composite model, which means that structural embeddings remain consistent during post-training. We conduct Supervised Fine-Tuning (SFT) on \(\theta_{L}\) using the curated dataset, followed by Direct Preference Optimization (DPO) [37] initialized from the SFT checkpoint to derive the final composite model. All details, including prompt template, data curation and post-training, are presented in Appendix B.2.  

\(\bullet\) Evolutionary Code Refinement for Combinatorial Optimization Problem. Prior work [30, 20, 29] leverages LLMs' code generation and algorithm design capabilities within Evolutionary Algorithms (EAs) to address combinatorial optimization problems through iterative feedback frameworks. The iterative nature of evolutionary algorithms introduces significant computational overhead as the primary limitation of prior approaches [30, 20, 29] for identifying optimal code snippets or algorithms to solve combinatorial optimization problems. Convergence typically requires numerous iterations, exacerbated by the prolonged execution times required for solver- based evaluation of generated code or algorithm candidates.  

Our evolutionary code optimization framework for combinatorial optimization adopts the core principles of prior work[30, 20, 29], with the significant distinction lying in the composite model learned in Step \(\bullet\) (see Figure 2 right panel). Our framework jointly processes both textual problem descriptions with algorithm discovery objectives and formal mathematical model of CO problems.