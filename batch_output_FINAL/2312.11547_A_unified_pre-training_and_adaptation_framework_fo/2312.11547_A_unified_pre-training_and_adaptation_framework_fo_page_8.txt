<center>Figure 2 Illustration of the proposed pre-training and fine-tuning architecture. In the pre-training stage, the bipartite graphs generated from Max-SAT clauses are used to train the MLP, bipartite GNN backbone (Bip-GNN(Â·)), and fully connected classification layers \(\mathrm{FC}(\cdot)\) . In the fine-tuning stage, the bipartite graphs generated by Max-SAT and the CO are treated as source and target domains and are separately fed into the MLP and Bip-GNN to obtain features. A discriminator is to obtain domain labels for domain adaptation. The features are passed through the classification layer to predict the labels of variable nodes. </center>  

where \(\alpha_{c_{j}\to x_{i}}\) denotes the attention score between clause \(c_{j}\) and variable \(x_{i}\) , \(\tilde{\mathbf{w}}_{Q}^{(l)}\) , \(\tilde{\mathbf{w}}_{K}^{(l)}\) , and \(\tilde{\mathbf{w}}_{V}^{(l)}\) are parameters, and \(\mathcal{N}(v_{x}(i))\) is the neighbor set of clause nodes for variable \(x_{i}\) .  

After the two steps of aggregation, we can obtain the updated features of variables \(\mathbf{X}^{(L)}\) and clauses \(\mathbf{C}^{(L)}\) where \(L\) is the number of layers for bipartite GNNs. The correlations between variables and clauses can be captured by the aggregation processes and the importance of neighbors can be learned by the attention mechanism. We can then build our framework based on the bipartite GNN backbone.  

### 3.4 Pre-Training and Fine-Tuning with Domain Adaptation  

In this subsection, we introduce the framework of our work for training as depicted in Figure 2. Our framework consists of two stages. The first stage is to pre- train our model by using massive samples generated from Max- SAT and the second stage is to further fine- tune the model with domain adaptation that combines samples from Max- SAT and CO problems.  

#### 3.4.1 Pre-Training  

In the pre- training stage, the goal is to learn the general knowledge from Max- SAT and obtain better parameter initialization that can be used for solving different CO problems. We first generate massive clauses from Max- SAT and then convert them into bipartite graphs.  

To generate Max- SAT clauses, we follow [48] and select different distributions to simulate different scenarios of problems: (1) In uniform distribution, the variables and clauses appear with the same frequency. The sizes of clauses also appear with the same frequency. The clause size refers to the number of variables within a clause. For example, given a clause \(x_{1} \lor x_{2} \lor \neg x_{3}\) , the clause size is three. (2) The single power- low distribution is a non- uniform distribution where most variables appear in low frequencies while only a few variables appear in high frequencies. The sizes of clauses also appear with the same frequency. (3) Double power- low distribution is also a non- uniform distribution that aims to simulate extremely uneven samples. Small clause size appears in high frequencies and the frequency decreases as the clause size increases.