Model counting competition 2020 url, 2020. https://mccompetition.org/2021/mc_description.html.
Model counting competition 2021 url, 2021. https://mccompetition.org/2021/mc_description.html.
Model counting competition 2022 url, 2022. https://mccompetition.org/2022/mc_description.html.
Sat competition 2022. https://satcompetition.github.io/2022/, 2022. Accessed: 2023- 08- 10.
Sat competition 2023. https://satcompetition.github.io/2023/, 2023. Accessed: 2023- 11- 23.
Tasniem Al- Yahya, Mohamed El Bachir Abdelkrim Menai, and Hassan Mathkour. Boosting the performance of cdc1- based sat solvers by exploiting backbones and backdoors. Algorithms, 15(9): 302, 2022.
Gilles Audemard and Laurent Simon. On the glucose sat solver. International Journal on Artificial Intelligence Tools, 27(01):1840001, 2018.
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.
Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez- Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261, 2018.
Armin Biere and Mathias Fleury. Chasing target phases. In Workshop on the Pragmatics of SAT, 2020.
Armin Biere and Mathias Fleury. Gimsatul, IsaSAT and Kissat entering the SAT Competition 2022. In Tomas Balyo, Marijn Heule, Markus Iser, Matti Järvisalo, and Martin Suda (eds.), Proc. of SAT Competition 2022 - Solver and Benchmark Descriptions, volume B- 2022- 1 of Department of Computer Science Series of Publications B, pp. 10- 11. University of Helsinki, 2022.
Armin Biere, Mathias Fleury, and Maximilian Heisinger. Cadical, kissat, paracooba entering the sat competition 2021. 2021. URL https://api.semanticscholar.org/CorpusID: 238996423.
Armin Biere, Nils Froleyks, and Wenxi Wang. Cadiback: Extracting backbones with cadical. In 26th International Conference on Theory and Applications of Satisfiability Testing (SAT 2023). Schloss Dagstuhl- Leibniz- Zentrum für Informatik, 2023.
Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. Measuring and relieving the oversmoothing problem for graph neural networks from the topological view. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pp. 3438- 3445, 2020.
Martin Davis, George Logemann, and Donald Loveland. A machine program for theorem- proving. Communications of the ACM, 5(7):394- 397, 1962.
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.
Niklas Eén and Niklas Sörensson. An extensible sat- solver. In International conference on theory and applications of satisfiability testing, pp. 502- 518. Springer, 2003.
Matthias Fey and Jan E. Lenssen. Fast graph representation learning with PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019.
Matthias Fey and Jan E. Lenssen. conv.gatconv. https://pytorch- geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATConv.html, 2023a.
Matthias Fey and Jan E. Lenssen. conv.ginconv. https://pytorch- geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GINConv.html, 2023b.
Johannes K Fichte, Markus Hecher, and Florim Hamiti. The model counting competition 2020. Journal of Experimental Algorithmics (JEA), 26:1- 26, 2021.
ABKFM Fleury and Maximilian Heisinger. Cadical, kissat, paracooba, plingeling and treengeling entering the sat competition 2020. SAT COMPETITION, 2020:50, 2020.
Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In International conference on machine learning, pp. 1263- 1272. PMLR, 2017.
Marco Gori, Gabriele Monfardini, and Franco Scarselli. A new model for learning in graph domains. In Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005., volume 2, pp. 729- 734. IEEE, 2005.
Youssef Hamadi, Said Jabbour, and Lakhdar Sais. Manysat: a parallel sat solver. Journal on Satisfiability, Boolean Modeling and Computation, 6(4):245- 262, 2010.
William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 1025- 1035, 2017.
Jesse Michael Han. Enhancing sat solvers with glue variable predictions. arXiv preprint arXiv:2007.02559, 2020.
Marijn JH Heule, Matti Juhani Järvisalo, Martin Suda, et al. Proceedings of SAT competition 2018: Solver and benchmark descriptions. 2018.
Holger H Hoos and Thomas Stützle. Satlib: An online resource for research on sat. Sat, 2000: 283- 292, 2000.
Mikoláš Janota. SAT solving in interactive configuration. PhD thesis, University College Dublin, 2010.
Sebastian Jaszczur, Michał Łuszczyk, and Henryk Michalewski. Neural heuristics for sat solving. arXiv preprint arXiv:2005.13406, 2020.
Philip Kilby, John Slaney, Sylvie Thiebaux, Toby Walsh, et al. Backbones and backdoors in satisfiability. In AAAI, volume 5, pp. 1368- 1373, 2005.
Thomas N Kipf and Max Welling. Semi- supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016.
Vitaly Kurin, Saad Godil, Shimon Whiteson, and Bryan Catanzaro. Improving SAT solver heuristics with graph networks and reinforcement learning. 2019.
Vitaly Kurin, Saad Godil, Shimon Whiteson, and Bryan Catanzaro. Improving SAT solver heuristic with graph networks and reinforcement learning. In Advances in Neural Information Processing Systems, 2020.
Massimo Lauria, Jan Elffers, Jakob Nordström, and Marc Vinyals. Cnfgcn: A generator of crafted benchmarks. In International Conference on Theory and Applications of Satisfiability Testing, pp. 464- 473. Springer, 2017.
Jia Hui Liang, Vijay Ganesh, Pascal Poupart, and Krzysztof Czarnecki. Learning rate based branching heuristic for sat solvers. In Theory and Applications of Satisfiability Testing- SAT 2016: 19th International Conference, Bordeaux, France, July 5- 8, 2016, Proceedings 19, pp. 123- 140. Springer, 2016.
Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017.
Joao Marques- Silva, Inês Lynce, and Sharad Malik. Conflict- driven clause learning sat solvers. In Handbook of Satisfiability: Second Edition. Part 1/Part 2, pp. 133- 182. IOS Press BV, 2021.
Joao P Marques- Silva and Karem A Sakallah. Grasp—a new search algorithm for satisfiability. In The Best of ICCAD, pp. 73- 89. Springer, 2003.
Ruben Martins, Vasco Manquinho, and Inês Lynce. An overview of parallel sat solving. Constraints, 17:304- 347, 2012.
Grégoire Mialon, Dexiong Chen, Margot Selosse, and Julien Mairal. Graphit: Encoding graph structure in transformers. arXiv preprint arXiv:2106.05667, 2021.
Erxue Min, Runfa Chen, Yatao Bian, Tingyang Xu, Kangfei Zhao, Wenbing Huang, Peilin Zhao, Junzhou Huang, Sophia Ananiadou, and Yu Rong. Transformer for graphs: An overview from architecture perspective. arXiv preprint arXiv:2202.08455, 2022.
Matthew W. Moskewicz, Conor F. Madigan, Ying Zhao, Lintao Zhang, and Sharad Malik. Chaff: Engineering an efficient sat solver. In Proceedings of the 38th Annual Design Automation Conference, DAC '01, pp. 530- 535, New York, NY, USA, 2001. Association for Computing Machinery.
Piotr Padlewski and Josip Djolonga. Scaling vision transformers to 22 billion parameters. https://ai.googleblog.com/2023/03/scaling- vision- transformers- to- 22. html, 2023.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high- performance deep learning library. arXiv preprint arXiv:1912.01703, 2019.
Knot Pipatsrisawat and Adnan Darwiche. A lightweight component caching scheme for satisfiability solvers. In Theory and Applications of Satisfiability Testing- SAT 2007: 10th International Conference, Lisbon, Portugal, May 28- 31, 2007. Proceedings 10, pp. 294- 299. Springer, 2007.
Yu Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying Wei, Wenbing Huang, and Junzhou Huang. Self- supervised graph transformer on large- scale molecular data. Advances in Neural Information Processing Systems, 33:12559- 12571, 2020.
Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61- 80, 2008.
Dominik Schreiber and Peter Sanders. Scalable sat solving in the cloud. In Theory and Applications of Satisfiability Testing- SAT 2021: 24th International Conference, Barcelona, Spain, July 5- 9, 2021, Proceedings 24, pp. 518- 534. Springer, 2021.
Daniel Selsam and Nikolaj Bjorner. Guiding high- performance SAT solvers with unsat- core predictions. In International Conference on Theory and Applications of Satisfiability Testing, pp. 336- 353. Springer, 2019.
Daniel Selsam, Matthew Lamm, Benedikt Bünz, Percy Liang, Leonardo de Moura, and David L Dill. Learning a SAT solver from single- bit supervision. arXiv preprint arXiv:1802.03685, 2018.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.
Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017.
Haoze Wu. Improving sat- solving with machine learning. In Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education, pp. 787- 788, 2017.
Zhanghao Wu, Paras Jain, Matthew Wright, Azalia Mirhoseini, Joseph E Gonzalez, and Ion Stoica. Representing long- range context for graph neural networks with global attention. Advances in Neural Information Processing Systems, 34:13266- 13279, 2021.
Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4- 24, 2020.
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? arXiv preprint arXiv:1810.00826, 2018.
Emre Yolcu and Barnabas Póczos. Learning local search heuristics for boolean satisfiability. In Advances in Neural Information Processing Systems, pp. 7992- 8003, 2019.
Ziwei Zhang and Yang Zhang. Elimination mechanism of glue variables for solving sat problems in linguistics. In The Asian Conference on Language, pp. 147- 167, 2021.
Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. Graph neural networks: A review of methods and applications. AI Open, 1:57- 81, 2020.
Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and Qing He. A comprehensive survey on transfer learning. Proceedings of the IEEE, 109(1):43- 76, 2020.
